{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py85-Cna3C-m"
      },
      "source": [
        "## HW2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7BIE8HEAA0m",
        "outputId": "7f5bd868-c04e-4706-a971-2505f5c2c4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE237Uh3ABKY",
        "outputId": "d8a88f26-2366-4e8f-9ce2-603ee1a8b06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# see more data augmentation https://pytorch.org/vision/stable/transforms.html\n",
        "mean = (0.5071, 0.4867, 0.4408)\n",
        "std = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "#參考 https://github.com/weiaicunzai/pytorch-cifar100/blob/master/utils.py\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "    #  transforms.RandomCrop(32, padding=4),\n",
        "    #  transforms.RandomHorizontalFlip(),\n",
        "    #  transforms.RandomRotation(15),\n",
        "     transforms.RandAugment(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)]) # calculte yourself\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)]) # calculte yourself \n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 100    # check\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tWvH0Nivzf2J"
      },
      "outputs": [],
      "source": [
        "def model_module(model, trainloader, testloader):\n",
        "\n",
        "  start = time.time()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-8, verbose=True)\n",
        "\n",
        "  total_epoch = 50\n",
        "  print_per_iteration = 100\n",
        "\n",
        "  train_acc=[]\n",
        "  train_loss=[]\n",
        "  test_acc=[]\n",
        "  test_loss=[]\n",
        "\n",
        "  min_acc=0\n",
        "\n",
        "  for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      \n",
        "\n",
        "          # print statistics\n",
        "          if (i+1) % print_per_iteration == 0:  \n",
        "              print(f'[ep {epoch + 1}][{i + 1:5d}/{len(trainloader):5d}] loss: {loss.item():.3f}')\n",
        "\n",
        "      # Test acc,loss in epoch\n",
        "      # fixed testing process\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "      with torch.no_grad():\n",
        "          for data in testloader:\n",
        "              images, labels = data\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              # calculate outputs by running images through the network\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              # the class with the highest energy is what we choose as prediction\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      test_acc.append(100 * correct / total)\n",
        "      test_loss.append(loss.cpu().numpy())\n",
        "      print('test loss', test_loss[-1])\n",
        "      print(f'test accuracy {test_acc[-1]:.2f} %')\n",
        "\n",
        "      # Train acc,loss in epoch\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "          for data in trainloader:\n",
        "              images, labels = data\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              # calculate outputs by running images through the network\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              # the class with the highest energy is what we choose as prediction\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      train_acc.append(100 * correct / total)\n",
        "      train_loss.append(loss.cpu().numpy())\n",
        "      print('train loss', train_loss[-1])\n",
        "      print(f'train accuracy {train_acc[-1]:.2f} %')\n",
        "\n",
        "      scheduler.step(test_loss[-1])\n",
        "      \n",
        "      if min_acc<test_acc[-1]:\n",
        "        min_acc = test_acc[-1]\n",
        "        torch.save(model, save_path)\n",
        "        print(\"model saved !\")\n",
        "      \n",
        "      print(\"--------------------------------------------------\")\n",
        "\n",
        "  end = time.time()\n",
        "  cost_time = end-start\n",
        "  return [cost_time, train_acc, train_loss, test_acc, test_loss]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zYnmObK6ll03"
      },
      "outputs": [],
      "source": [
        "class Identity(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Identity, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 3.637\n",
            "[ep 1][  200/  391] loss: 3.202\n",
            "[ep 1][  300/  391] loss: 2.637\n",
            "test loss 2.4003334\n",
            "test accuracy 48.15 %\n",
            "train loss 2.4624274\n",
            "train accuracy 45.12 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.847\n",
            "[ep 2][  200/  391] loss: 1.938\n",
            "[ep 2][  300/  391] loss: 1.682\n",
            "test loss 1.8726538\n",
            "test accuracy 59.26 %\n",
            "train loss 1.4657743\n",
            "train accuracy 58.99 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.579\n",
            "[ep 3][  200/  391] loss: 1.274\n",
            "[ep 3][  300/  391] loss: 1.568\n",
            "test loss 1.5819621\n",
            "test accuracy 64.01 %\n",
            "train loss 1.0777464\n",
            "train accuracy 67.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 1.093\n",
            "[ep 4][  200/  391] loss: 1.167\n",
            "[ep 4][  300/  391] loss: 1.086\n",
            "test loss 1.4878446\n",
            "test accuracy 66.81 %\n",
            "train loss 1.0992831\n",
            "train accuracy 72.88 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.892\n",
            "[ep 5][  200/  391] loss: 1.006\n",
            "[ep 5][  300/  391] loss: 1.039\n",
            "test loss 1.3958259\n",
            "test accuracy 68.89 %\n",
            "train loss 1.0488416\n",
            "train accuracy 77.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.787\n",
            "[ep 6][  200/  391] loss: 0.929\n",
            "[ep 6][  300/  391] loss: 0.730\n",
            "test loss 1.0215398\n",
            "test accuracy 69.77 %\n",
            "train loss 0.6276665\n",
            "train accuracy 81.06 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.666\n",
            "[ep 7][  200/  391] loss: 0.668\n",
            "[ep 7][  300/  391] loss: 0.712\n",
            "test loss 0.97509384\n",
            "test accuracy 70.80 %\n",
            "train loss 0.53730065\n",
            "train accuracy 84.01 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.496\n",
            "[ep 8][  200/  391] loss: 0.558\n",
            "[ep 8][  300/  391] loss: 0.586\n",
            "test loss 1.2530018\n",
            "test accuracy 71.49 %\n",
            "train loss 0.45600444\n",
            "train accuracy 86.53 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.555\n",
            "[ep 9][  200/  391] loss: 0.448\n",
            "[ep 9][  300/  391] loss: 0.478\n",
            "test loss 1.0162089\n",
            "test accuracy 71.20 %\n",
            "train loss 0.2516404\n",
            "train accuracy 88.15 %\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.502\n",
            "[ep 10][  200/  391] loss: 0.451\n",
            "[ep 10][  300/  391] loss: 0.554\n",
            "test loss 0.7314993\n",
            "test accuracy 71.68 %\n",
            "train loss 0.2703365\n",
            "train accuracy 89.51 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.419\n",
            "[ep 11][  200/  391] loss: 0.607\n",
            "[ep 11][  300/  391] loss: 0.370\n",
            "test loss 0.804886\n",
            "test accuracy 71.81 %\n",
            "train loss 0.40812293\n",
            "train accuracy 90.70 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.437\n",
            "[ep 12][  200/  391] loss: 0.344\n",
            "[ep 12][  300/  391] loss: 0.551\n",
            "test loss 0.6648215\n",
            "test accuracy 71.57 %\n",
            "train loss 0.20086046\n",
            "train accuracy 91.67 %\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.315\n",
            "[ep 13][  200/  391] loss: 0.324\n",
            "[ep 13][  300/  391] loss: 0.425\n",
            "test loss 0.518017\n",
            "test accuracy 71.85 %\n",
            "train loss 0.2733325\n",
            "train accuracy 92.02 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.405\n",
            "[ep 14][  200/  391] loss: 0.374\n",
            "[ep 14][  300/  391] loss: 0.339\n",
            "test loss 0.81360734\n",
            "test accuracy 71.97 %\n",
            "train loss 0.15991703\n",
            "train accuracy 92.62 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.219\n",
            "[ep 15][  200/  391] loss: 0.294\n",
            "[ep 15][  300/  391] loss: 0.257\n",
            "test loss 0.6842816\n",
            "test accuracy 72.10 %\n",
            "train loss 0.31888574\n",
            "train accuracy 93.37 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.288\n",
            "[ep 16][  200/  391] loss: 0.226\n",
            "[ep 16][  300/  391] loss: 0.259\n",
            "test loss 0.8416496\n",
            "test accuracy 71.98 %\n",
            "train loss 0.12959762\n",
            "train accuracy 93.76 %\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.192\n",
            "[ep 17][  200/  391] loss: 0.268\n",
            "[ep 17][  300/  391] loss: 0.282\n",
            "test loss 0.88639635\n",
            "test accuracy 71.90 %\n",
            "train loss 0.2314188\n",
            "train accuracy 93.88 %\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-05.\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.246\n",
            "[ep 18][  200/  391] loss: 0.165\n",
            "[ep 18][  300/  391] loss: 0.104\n",
            "test loss 0.6477374\n",
            "test accuracy 73.14 %\n",
            "train loss 0.15781042\n",
            "train accuracy 96.08 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.221\n",
            "[ep 19][  200/  391] loss: 0.204\n",
            "[ep 19][  300/  391] loss: 0.211\n",
            "test loss 0.56584066\n",
            "test accuracy 73.21 %\n",
            "train loss 0.25402698\n",
            "train accuracy 96.25 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.156\n",
            "[ep 20][  200/  391] loss: 0.081\n",
            "[ep 20][  300/  391] loss: 0.091\n",
            "test loss 0.80760473\n",
            "test accuracy 73.37 %\n",
            "train loss 0.15502802\n",
            "train accuracy 96.64 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.124\n",
            "[ep 21][  200/  391] loss: 0.162\n",
            "[ep 21][  300/  391] loss: 0.151\n",
            "test loss 0.77662045\n",
            "test accuracy 73.12 %\n",
            "train loss 0.11535587\n",
            "train accuracy 96.49 %\n",
            "Epoch 00021: reducing learning rate of group 0 to 2.5000e-05.\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.067\n",
            "[ep 22][  200/  391] loss: 0.136\n",
            "[ep 22][  300/  391] loss: 0.081\n",
            "test loss 0.89319026\n",
            "test accuracy 73.37 %\n",
            "train loss 0.11244528\n",
            "train accuracy 97.32 %\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.079\n",
            "[ep 23][  200/  391] loss: 0.140\n",
            "[ep 23][  300/  391] loss: 0.132\n",
            "test loss 0.8824798\n",
            "test accuracy 73.84 %\n",
            "train loss 0.05010267\n",
            "train accuracy 97.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.067\n",
            "[ep 24][  200/  391] loss: 0.106\n",
            "[ep 24][  300/  391] loss: 0.079\n",
            "test loss 0.8976893\n",
            "test accuracy 73.71 %\n",
            "train loss 0.120591305\n",
            "train accuracy 97.58 %\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.107\n",
            "[ep 25][  200/  391] loss: 0.103\n",
            "[ep 25][  300/  391] loss: 0.132\n",
            "test loss 0.9153238\n",
            "test accuracy 73.63 %\n",
            "train loss 0.22622316\n",
            "train accuracy 97.73 %\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.2500e-05.\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.073\n",
            "[ep 26][  200/  391] loss: 0.072\n",
            "[ep 26][  300/  391] loss: 0.087\n",
            "test loss 0.9278257\n",
            "test accuracy 73.93 %\n",
            "train loss 0.104242764\n",
            "train accuracy 97.92 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.125\n",
            "[ep 27][  200/  391] loss: 0.057\n",
            "[ep 27][  300/  391] loss: 0.075\n",
            "test loss 0.86333686\n",
            "test accuracy 73.97 %\n",
            "train loss 0.116032496\n",
            "train accuracy 97.95 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.075\n",
            "[ep 28][  200/  391] loss: 0.022\n",
            "[ep 28][  300/  391] loss: 0.070\n",
            "test loss 0.91572255\n",
            "test accuracy 73.94 %\n",
            "train loss 0.120528\n",
            "train accuracy 98.07 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.039\n",
            "[ep 29][  200/  391] loss: 0.058\n",
            "[ep 29][  300/  391] loss: 0.067\n",
            "test loss 0.87748337\n",
            "test accuracy 74.17 %\n",
            "train loss 0.086167224\n",
            "train accuracy 98.25 %\n",
            "Epoch 00029: reducing learning rate of group 0 to 6.2500e-06.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.175\n",
            "[ep 30][  200/  391] loss: 0.037\n",
            "[ep 30][  300/  391] loss: 0.036\n",
            "test loss 0.8164839\n",
            "test accuracy 74.22 %\n",
            "train loss 0.02467906\n",
            "train accuracy 98.27 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.058\n",
            "[ep 31][  200/  391] loss: 0.064\n",
            "[ep 31][  300/  391] loss: 0.053\n",
            "test loss 0.816124\n",
            "test accuracy 74.24 %\n",
            "train loss 0.0623331\n",
            "train accuracy 98.22 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.071\n",
            "[ep 32][  200/  391] loss: 0.028\n",
            "[ep 32][  300/  391] loss: 0.047\n",
            "test loss 0.8543569\n",
            "test accuracy 74.03 %\n",
            "train loss 0.022723023\n",
            "train accuracy 98.22 %\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.063\n",
            "[ep 33][  200/  391] loss: 0.079\n",
            "[ep 33][  300/  391] loss: 0.052\n",
            "test loss 0.8372404\n",
            "test accuracy 73.91 %\n",
            "train loss 0.061446935\n",
            "train accuracy 98.31 %\n",
            "Epoch 00033: reducing learning rate of group 0 to 3.1250e-06.\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.051\n",
            "[ep 34][  200/  391] loss: 0.047\n",
            "[ep 34][  300/  391] loss: 0.108\n",
            "test loss 0.87975913\n",
            "test accuracy 74.19 %\n",
            "train loss 0.06949653\n",
            "train accuracy 98.41 %\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.040\n",
            "[ep 35][  200/  391] loss: 0.035\n",
            "[ep 35][  300/  391] loss: 0.029\n",
            "test loss 0.8073808\n",
            "test accuracy 74.14 %\n",
            "train loss 0.031553213\n",
            "train accuracy 98.32 %\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.051\n",
            "[ep 36][  200/  391] loss: 0.053\n",
            "[ep 36][  300/  391] loss: 0.072\n",
            "test loss 0.78668255\n",
            "test accuracy 74.22 %\n",
            "train loss 0.084898\n",
            "train accuracy 98.48 %\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.081\n",
            "[ep 37][  200/  391] loss: 0.042\n",
            "[ep 37][  300/  391] loss: 0.082\n",
            "test loss 0.77975\n",
            "test accuracy 74.28 %\n",
            "train loss 0.018509833\n",
            "train accuracy 98.49 %\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.5625e-06.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.026\n",
            "[ep 38][  200/  391] loss: 0.059\n",
            "[ep 38][  300/  391] loss: 0.109\n",
            "test loss 0.7915651\n",
            "test accuracy 74.27 %\n",
            "train loss 0.16862287\n",
            "train accuracy 98.41 %\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.047\n",
            "[ep 39][  200/  391] loss: 0.038\n",
            "[ep 39][  300/  391] loss: 0.054\n",
            "test loss 0.8003211\n",
            "test accuracy 74.34 %\n",
            "train loss 0.07221639\n",
            "train accuracy 98.42 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.053\n",
            "[ep 40][  200/  391] loss: 0.066\n",
            "[ep 40][  300/  391] loss: 0.057\n",
            "test loss 0.7935326\n",
            "test accuracy 74.28 %\n",
            "train loss 0.067583695\n",
            "train accuracy 98.51 %\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.028\n",
            "[ep 41][  200/  391] loss: 0.105\n",
            "[ep 41][  300/  391] loss: 0.033\n",
            "test loss 0.8044179\n",
            "test accuracy 74.35 %\n",
            "train loss 0.14012437\n",
            "train accuracy 98.45 %\n",
            "Epoch 00041: reducing learning rate of group 0 to 7.8125e-07.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.071\n",
            "[ep 42][  200/  391] loss: 0.035\n",
            "[ep 42][  300/  391] loss: 0.075\n",
            "test loss 0.80689466\n",
            "test accuracy 74.28 %\n",
            "train loss 0.059529163\n",
            "train accuracy 98.45 %\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.038\n",
            "[ep 43][  200/  391] loss: 0.043\n",
            "[ep 43][  300/  391] loss: 0.028\n",
            "test loss 0.81036973\n",
            "test accuracy 74.34 %\n",
            "train loss 0.10479394\n",
            "train accuracy 98.49 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.034\n",
            "[ep 44][  200/  391] loss: 0.079\n",
            "[ep 44][  300/  391] loss: 0.027\n",
            "test loss 0.8211254\n",
            "test accuracy 74.34 %\n",
            "train loss 0.034823455\n",
            "train accuracy 98.45 %\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.044\n",
            "[ep 45][  200/  391] loss: 0.035\n",
            "[ep 45][  300/  391] loss: 0.029\n",
            "test loss 0.82144755\n",
            "test accuracy 74.33 %\n",
            "train loss 0.027686229\n",
            "train accuracy 98.48 %\n",
            "Epoch 00045: reducing learning rate of group 0 to 3.9063e-07.\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.072\n",
            "[ep 46][  200/  391] loss: 0.118\n",
            "[ep 46][  300/  391] loss: 0.063\n",
            "test loss 0.8214789\n",
            "test accuracy 74.40 %\n",
            "train loss 0.038875505\n",
            "train accuracy 98.43 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.029\n",
            "[ep 47][  200/  391] loss: 0.097\n",
            "[ep 47][  300/  391] loss: 0.054\n",
            "test loss 0.81917244\n",
            "test accuracy 74.36 %\n",
            "train loss 0.068436146\n",
            "train accuracy 98.49 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.033\n",
            "[ep 48][  200/  391] loss: 0.032\n",
            "[ep 48][  300/  391] loss: 0.067\n",
            "test loss 0.8092251\n",
            "test accuracy 74.35 %\n",
            "train loss 0.1261712\n",
            "train accuracy 98.48 %\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.061\n",
            "[ep 49][  200/  391] loss: 0.138\n",
            "[ep 49][  300/  391] loss: 0.055\n",
            "test loss 0.8109314\n",
            "test accuracy 74.33 %\n",
            "train loss 0.041582234\n",
            "train accuracy 98.51 %\n",
            "Epoch 00049: reducing learning rate of group 0 to 1.9531e-07.\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.055\n",
            "[ep 50][  200/  391] loss: 0.054\n",
            "[ep 50][  300/  391] loss: 0.050\n",
            "test loss 0.8106099\n",
            "test accuracy 74.32 %\n",
            "train loss 0.054932635\n",
            "train accuracy 98.48 %\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Eclab\\anaconda3\\envs\\pytorch37\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(512, num_classes)\n",
        "# print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet18_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet18 = model_module(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet18\",stats_resnet18) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 3.382\n",
            "[ep 1][  200/  391] loss: 2.720\n",
            "[ep 1][  300/  391] loss: 2.150\n",
            "test loss 1.8308368\n",
            "test accuracy 58.09 %\n",
            "train loss 1.7909819\n",
            "train accuracy 55.55 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.444\n",
            "[ep 2][  200/  391] loss: 1.736\n",
            "[ep 2][  300/  391] loss: 1.400\n",
            "test loss 1.2262957\n",
            "test accuracy 68.29 %\n",
            "train loss 0.9529275\n",
            "train accuracy 69.36 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.053\n",
            "[ep 3][  200/  391] loss: 0.873\n",
            "[ep 3][  300/  391] loss: 1.173\n",
            "test loss 1.2449962\n",
            "test accuracy 72.42 %\n",
            "train loss 0.70791566\n",
            "train accuracy 76.79 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.871\n",
            "[ep 4][  200/  391] loss: 0.836\n",
            "[ep 4][  300/  391] loss: 0.820\n",
            "test loss 0.6412384\n",
            "test accuracy 73.56 %\n",
            "train loss 0.57736623\n",
            "train accuracy 81.31 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.759\n",
            "[ep 5][  200/  391] loss: 0.745\n",
            "[ep 5][  300/  391] loss: 0.670\n",
            "test loss 1.0309036\n",
            "test accuracy 74.68 %\n",
            "train loss 0.52522075\n",
            "train accuracy 84.33 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.657\n",
            "[ep 6][  200/  391] loss: 0.494\n",
            "[ep 6][  300/  391] loss: 0.592\n",
            "test loss 0.7899721\n",
            "test accuracy 75.28 %\n",
            "train loss 0.5166403\n",
            "train accuracy 86.57 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.392\n",
            "[ep 7][  200/  391] loss: 0.488\n",
            "[ep 7][  300/  391] loss: 0.556\n",
            "test loss 0.8559647\n",
            "test accuracy 75.50 %\n",
            "train loss 0.461454\n",
            "train accuracy 88.74 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.289\n",
            "[ep 8][  200/  391] loss: 0.394\n",
            "[ep 8][  300/  391] loss: 0.377\n",
            "test loss 0.6879934\n",
            "test accuracy 75.94 %\n",
            "train loss 0.13967703\n",
            "train accuracy 90.07 %\n",
            "Epoch 00008: reducing learning rate of group 0 to 5.0000e-05.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.368\n",
            "[ep 9][  200/  391] loss: 0.320\n",
            "[ep 9][  300/  391] loss: 0.152\n",
            "test loss 0.84285396\n",
            "test accuracy 77.85 %\n",
            "train loss 0.24841392\n",
            "train accuracy 93.42 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.246\n",
            "[ep 10][  200/  391] loss: 0.213\n",
            "[ep 10][  300/  391] loss: 0.218\n",
            "test loss 0.5541571\n",
            "test accuracy 78.19 %\n",
            "train loss 0.16583043\n",
            "train accuracy 94.57 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.193\n",
            "[ep 11][  200/  391] loss: 0.407\n",
            "[ep 11][  300/  391] loss: 0.245\n",
            "test loss 0.868346\n",
            "test accuracy 77.67 %\n",
            "train loss 0.22779384\n",
            "train accuracy 95.05 %\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.137\n",
            "[ep 12][  200/  391] loss: 0.164\n",
            "[ep 12][  300/  391] loss: 0.216\n",
            "test loss 0.9078547\n",
            "test accuracy 77.47 %\n",
            "train loss 0.22019589\n",
            "train accuracy 95.25 %\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.137\n",
            "[ep 13][  200/  391] loss: 0.189\n",
            "[ep 13][  300/  391] loss: 0.301\n",
            "test loss 0.8270589\n",
            "test accuracy 77.73 %\n",
            "train loss 0.09258046\n",
            "train accuracy 95.78 %\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.060\n",
            "[ep 14][  200/  391] loss: 0.182\n",
            "[ep 14][  300/  391] loss: 0.209\n",
            "test loss 0.7627455\n",
            "test accuracy 77.73 %\n",
            "train loss 0.16127394\n",
            "train accuracy 95.91 %\n",
            "Epoch 00014: reducing learning rate of group 0 to 2.5000e-05.\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.083\n",
            "[ep 15][  200/  391] loss: 0.073\n",
            "[ep 15][  300/  391] loss: 0.117\n",
            "test loss 0.9027975\n",
            "test accuracy 78.83 %\n",
            "train loss 0.19647685\n",
            "train accuracy 96.85 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.126\n",
            "[ep 16][  200/  391] loss: 0.146\n",
            "[ep 16][  300/  391] loss: 0.128\n",
            "test loss 0.76713526\n",
            "test accuracy 78.44 %\n",
            "train loss 0.03604623\n",
            "train accuracy 97.06 %\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.105\n",
            "[ep 17][  200/  391] loss: 0.099\n",
            "[ep 17][  300/  391] loss: 0.068\n",
            "test loss 0.6410282\n",
            "test accuracy 78.30 %\n",
            "train loss 0.11809461\n",
            "train accuracy 97.38 %\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.101\n",
            "[ep 18][  200/  391] loss: 0.079\n",
            "[ep 18][  300/  391] loss: 0.070\n",
            "test loss 0.80097467\n",
            "test accuracy 78.52 %\n",
            "train loss 0.10768135\n",
            "train accuracy 97.35 %\n",
            "Epoch 00018: reducing learning rate of group 0 to 1.2500e-05.\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.040\n",
            "[ep 19][  200/  391] loss: 0.095\n",
            "[ep 19][  300/  391] loss: 0.048\n",
            "test loss 0.81365234\n",
            "test accuracy 78.90 %\n",
            "train loss 0.07841052\n",
            "train accuracy 97.76 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.142\n",
            "[ep 20][  200/  391] loss: 0.070\n",
            "[ep 20][  300/  391] loss: 0.104\n",
            "test loss 0.97482544\n",
            "test accuracy 78.97 %\n",
            "train loss 0.15736352\n",
            "train accuracy 97.99 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.049\n",
            "[ep 21][  200/  391] loss: 0.037\n",
            "[ep 21][  300/  391] loss: 0.090\n",
            "test loss 0.97119766\n",
            "test accuracy 79.21 %\n",
            "train loss 0.043809414\n",
            "train accuracy 98.10 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.124\n",
            "[ep 22][  200/  391] loss: 0.049\n",
            "[ep 22][  300/  391] loss: 0.073\n",
            "test loss 0.9604933\n",
            "test accuracy 79.25 %\n",
            "train loss 0.048954394\n",
            "train accuracy 98.00 %\n",
            "Epoch 00022: reducing learning rate of group 0 to 6.2500e-06.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.035\n",
            "[ep 23][  200/  391] loss: 0.136\n",
            "[ep 23][  300/  391] loss: 0.077\n",
            "test loss 0.86385703\n",
            "test accuracy 79.41 %\n",
            "train loss 0.08179041\n",
            "train accuracy 98.26 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.112\n",
            "[ep 24][  200/  391] loss: 0.040\n",
            "[ep 24][  300/  391] loss: 0.109\n",
            "test loss 0.90049535\n",
            "test accuracy 79.51 %\n",
            "train loss 0.093909\n",
            "train accuracy 98.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.092\n",
            "[ep 25][  200/  391] loss: 0.107\n",
            "[ep 25][  300/  391] loss: 0.072\n",
            "test loss 0.83919895\n",
            "test accuracy 79.20 %\n",
            "train loss 0.11408681\n",
            "train accuracy 98.49 %\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.062\n",
            "[ep 26][  200/  391] loss: 0.134\n",
            "[ep 26][  300/  391] loss: 0.034\n",
            "test loss 0.7556789\n",
            "test accuracy 79.39 %\n",
            "train loss 0.0902852\n",
            "train accuracy 98.45 %\n",
            "Epoch 00026: reducing learning rate of group 0 to 3.1250e-06.\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.059\n",
            "[ep 27][  200/  391] loss: 0.062\n",
            "[ep 27][  300/  391] loss: 0.102\n",
            "test loss 0.7871965\n",
            "test accuracy 79.37 %\n",
            "train loss 0.019521842\n",
            "train accuracy 98.58 %\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.070\n",
            "[ep 28][  200/  391] loss: 0.010\n",
            "[ep 28][  300/  391] loss: 0.071\n",
            "test loss 0.7593135\n",
            "test accuracy 79.42 %\n",
            "train loss 0.05365008\n",
            "train accuracy 98.43 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.091\n",
            "[ep 29][  200/  391] loss: 0.027\n",
            "[ep 29][  300/  391] loss: 0.030\n",
            "test loss 0.8093505\n",
            "test accuracy 79.34 %\n",
            "train loss 0.08946228\n",
            "train accuracy 98.53 %\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.133\n",
            "[ep 30][  200/  391] loss: 0.066\n",
            "[ep 30][  300/  391] loss: 0.061\n",
            "test loss 0.75852436\n",
            "test accuracy 79.54 %\n",
            "train loss 0.076568484\n",
            "train accuracy 98.60 %\n",
            "Epoch 00030: reducing learning rate of group 0 to 1.5625e-06.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.056\n",
            "[ep 31][  200/  391] loss: 0.017\n",
            "[ep 31][  300/  391] loss: 0.048\n",
            "test loss 0.76663214\n",
            "test accuracy 79.49 %\n",
            "train loss 0.055842288\n",
            "train accuracy 98.60 %\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.075\n",
            "[ep 32][  200/  391] loss: 0.047\n",
            "[ep 32][  300/  391] loss: 0.021\n",
            "test loss 0.7924554\n",
            "test accuracy 79.48 %\n",
            "train loss 0.10268402\n",
            "train accuracy 98.64 %\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.054\n",
            "[ep 33][  200/  391] loss: 0.040\n",
            "[ep 33][  300/  391] loss: 0.095\n",
            "test loss 0.77281696\n",
            "test accuracy 79.62 %\n",
            "train loss 0.081964396\n",
            "train accuracy 98.56 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.043\n",
            "[ep 34][  200/  391] loss: 0.075\n",
            "[ep 34][  300/  391] loss: 0.037\n",
            "test loss 0.76192015\n",
            "test accuracy 79.62 %\n",
            "train loss 0.034794986\n",
            "train accuracy 98.67 %\n",
            "Epoch 00034: reducing learning rate of group 0 to 7.8125e-07.\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.084\n",
            "[ep 35][  200/  391] loss: 0.015\n",
            "[ep 35][  300/  391] loss: 0.049\n",
            "test loss 0.7639114\n",
            "test accuracy 79.65 %\n",
            "train loss 0.017364424\n",
            "train accuracy 98.67 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.057\n",
            "[ep 36][  200/  391] loss: 0.021\n",
            "[ep 36][  300/  391] loss: 0.044\n",
            "test loss 0.76948845\n",
            "test accuracy 79.57 %\n",
            "train loss 0.094478905\n",
            "train accuracy 98.57 %\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.051\n",
            "[ep 37][  200/  391] loss: 0.177\n",
            "[ep 37][  300/  391] loss: 0.054\n",
            "test loss 0.7756774\n",
            "test accuracy 79.57 %\n",
            "train loss 0.011499495\n",
            "train accuracy 98.72 %\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.058\n",
            "[ep 38][  200/  391] loss: 0.050\n",
            "[ep 38][  300/  391] loss: 0.047\n",
            "test loss 0.78779596\n",
            "test accuracy 79.59 %\n",
            "train loss 0.06480764\n",
            "train accuracy 98.70 %\n",
            "Epoch 00038: reducing learning rate of group 0 to 3.9063e-07.\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.019\n",
            "[ep 39][  200/  391] loss: 0.029\n",
            "[ep 39][  300/  391] loss: 0.032\n",
            "test loss 0.7889992\n",
            "test accuracy 79.59 %\n",
            "train loss 0.03343091\n",
            "train accuracy 98.68 %\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.029\n",
            "[ep 40][  200/  391] loss: 0.020\n",
            "[ep 40][  300/  391] loss: 0.046\n",
            "test loss 0.7867792\n",
            "test accuracy 79.57 %\n",
            "train loss 0.024651261\n",
            "train accuracy 98.67 %\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.022\n",
            "[ep 41][  200/  391] loss: 0.070\n",
            "[ep 41][  300/  391] loss: 0.110\n",
            "test loss 0.7830156\n",
            "test accuracy 79.56 %\n",
            "train loss 0.05378254\n",
            "train accuracy 98.70 %\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.094\n",
            "[ep 42][  200/  391] loss: 0.048\n",
            "[ep 42][  300/  391] loss: 0.032\n",
            "test loss 0.7765023\n",
            "test accuracy 79.59 %\n",
            "train loss 0.06356226\n",
            "train accuracy 98.68 %\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.9531e-07.\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.034\n",
            "[ep 43][  200/  391] loss: 0.105\n",
            "[ep 43][  300/  391] loss: 0.034\n",
            "test loss 0.77587247\n",
            "test accuracy 79.59 %\n",
            "train loss 0.016750738\n",
            "train accuracy 98.75 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.023\n",
            "[ep 44][  200/  391] loss: 0.062\n",
            "[ep 44][  300/  391] loss: 0.068\n",
            "test loss 0.77740514\n",
            "test accuracy 79.54 %\n",
            "train loss 0.028287366\n",
            "train accuracy 98.76 %\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.135\n",
            "[ep 45][  200/  391] loss: 0.039\n",
            "[ep 45][  300/  391] loss: 0.061\n",
            "test loss 0.7775559\n",
            "test accuracy 79.60 %\n",
            "train loss 0.038154066\n",
            "train accuracy 98.78 %\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.036\n",
            "[ep 46][  200/  391] loss: 0.074\n",
            "[ep 46][  300/  391] loss: 0.040\n",
            "test loss 0.775166\n",
            "test accuracy 79.61 %\n",
            "train loss 0.019853594\n",
            "train accuracy 98.72 %\n",
            "Epoch 00046: reducing learning rate of group 0 to 9.7656e-08.\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.026\n",
            "[ep 47][  200/  391] loss: 0.089\n",
            "[ep 47][  300/  391] loss: 0.040\n",
            "test loss 0.77656317\n",
            "test accuracy 79.59 %\n",
            "train loss 0.03255228\n",
            "train accuracy 98.81 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.075\n",
            "[ep 48][  200/  391] loss: 0.092\n",
            "[ep 48][  300/  391] loss: 0.055\n",
            "test loss 0.7748046\n",
            "test accuracy 79.59 %\n",
            "train loss 0.059078824\n",
            "train accuracy 98.79 %\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.040\n",
            "[ep 49][  200/  391] loss: 0.056\n",
            "[ep 49][  300/  391] loss: 0.052\n",
            "test loss 0.7754618\n",
            "test accuracy 79.58 %\n",
            "train loss 0.044848084\n",
            "train accuracy 98.63 %\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.038\n",
            "[ep 50][  200/  391] loss: 0.088\n",
            "[ep 50][  300/  391] loss: 0.018\n",
            "test loss 0.7736416\n",
            "test accuracy 79.61 %\n",
            "train loss 0.033860598\n",
            "train accuracy 98.75 %\n",
            "Epoch 00050: reducing learning rate of group 0 to 4.8828e-08.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet34(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(512, num_classes)\n",
        "# print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet34_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet34 = model_module(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet34\",stats_resnet34) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d2455034718144608cfb3f2a78bd6e13",
            "d2f02a019e5b4eae9b3e5c4b637d6f7a",
            "9601075326d34a4aa5b10b2b97bdc1ff",
            "56301a7fb8704a039aa75b6a6da58e63",
            "43631bbb9ed14d59b3db96cc2611b9ae",
            "b7061b708b734d67aa37369ae81d0b66",
            "964e52c6c4ff411ebc05a3f9167ea5bb",
            "a04ac7f8dfd646d69aecf5e6a3a442de",
            "ece6d1b16bf1411b8265687d7bff48e5",
            "6c7b0ba64f47485f822596253f519610",
            "f41ae248d3c945c6aa0a4e7f0ace37f4"
          ]
        },
        "id": "XiU4pXm_fJ3F",
        "outputId": "cd2db136-3af9-4000-b77d-fb3ac0c79d4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Eclab/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:08<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 3.331\n",
            "[ep 1][  200/  391] loss: 2.414\n",
            "[ep 1][  300/  391] loss: 1.899\n",
            "test loss 2.0989385\n",
            "test accuracy 56.70 %\n",
            "train loss 2.0392523\n",
            "train accuracy 54.23 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.701\n",
            "[ep 2][  200/  391] loss: 1.273\n",
            "[ep 2][  300/  391] loss: 1.384\n",
            "test loss 1.467102\n",
            "test accuracy 66.29 %\n",
            "train loss 1.3760376\n",
            "train accuracy 68.28 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.190\n",
            "[ep 3][  200/  391] loss: 0.855\n",
            "[ep 3][  300/  391] loss: 0.971\n",
            "test loss 1.2384456\n",
            "test accuracy 69.95 %\n",
            "train loss 0.9702525\n",
            "train accuracy 74.28 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.684\n",
            "[ep 4][  200/  391] loss: 0.810\n",
            "[ep 4][  300/  391] loss: 0.737\n",
            "test loss 1.262459\n",
            "test accuracy 71.08 %\n",
            "train loss 0.7840253\n",
            "train accuracy 78.98 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.590\n",
            "[ep 5][  200/  391] loss: 0.750\n",
            "[ep 5][  300/  391] loss: 0.877\n",
            "test loss 0.9750194\n",
            "test accuracy 73.27 %\n",
            "train loss 0.5641035\n",
            "train accuracy 82.64 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.566\n",
            "[ep 6][  200/  391] loss: 0.509\n",
            "[ep 6][  300/  391] loss: 0.520\n",
            "test loss 1.087746\n",
            "test accuracy 73.76 %\n",
            "train loss 0.7009374\n",
            "train accuracy 85.24 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.482\n",
            "[ep 7][  200/  391] loss: 0.564\n",
            "[ep 7][  300/  391] loss: 0.432\n",
            "test loss 1.0531412\n",
            "test accuracy 73.97 %\n",
            "train loss 0.51596826\n",
            "train accuracy 87.08 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.416\n",
            "[ep 8][  200/  391] loss: 0.543\n",
            "[ep 8][  300/  391] loss: 0.663\n",
            "test loss 1.245735\n",
            "test accuracy 74.59 %\n",
            "train loss 0.4715342\n",
            "train accuracy 88.14 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.463\n",
            "[ep 9][  200/  391] loss: 0.403\n",
            "[ep 9][  300/  391] loss: 0.523\n",
            "test loss 1.1281393\n",
            "test accuracy 74.36 %\n",
            "train loss 0.1890501\n",
            "train accuracy 89.57 %\n",
            "Epoch 00009: reducing learning rate of group 0 to 5.0000e-05.\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.198\n",
            "[ep 10][  200/  391] loss: 0.278\n",
            "[ep 10][  300/  391] loss: 0.344\n",
            "test loss 1.1260552\n",
            "test accuracy 76.53 %\n",
            "train loss 0.10445356\n",
            "train accuracy 93.34 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.166\n",
            "[ep 11][  200/  391] loss: 0.285\n",
            "[ep 11][  300/  391] loss: 0.164\n",
            "test loss 1.1854467\n",
            "test accuracy 76.83 %\n",
            "train loss 0.19766292\n",
            "train accuracy 94.20 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.271\n",
            "[ep 12][  200/  391] loss: 0.130\n",
            "[ep 12][  300/  391] loss: 0.262\n",
            "test loss 0.92281085\n",
            "test accuracy 76.95 %\n",
            "train loss 0.18834788\n",
            "train accuracy 94.64 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.196\n",
            "[ep 13][  200/  391] loss: 0.236\n",
            "[ep 13][  300/  391] loss: 0.183\n",
            "test loss 1.0571499\n",
            "test accuracy 76.72 %\n",
            "train loss 0.16780832\n",
            "train accuracy 94.98 %\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.139\n",
            "[ep 14][  200/  391] loss: 0.332\n",
            "[ep 14][  300/  391] loss: 0.184\n",
            "test loss 1.1903399\n",
            "test accuracy 76.28 %\n",
            "train loss 0.19910854\n",
            "train accuracy 94.90 %\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.138\n",
            "[ep 15][  200/  391] loss: 0.085\n",
            "[ep 15][  300/  391] loss: 0.149\n",
            "test loss 1.0503628\n",
            "test accuracy 76.19 %\n",
            "train loss 0.24458213\n",
            "train accuracy 95.39 %\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.132\n",
            "[ep 16][  200/  391] loss: 0.204\n",
            "[ep 16][  300/  391] loss: 0.066\n",
            "test loss 1.0167096\n",
            "test accuracy 76.30 %\n",
            "train loss 0.07337029\n",
            "train accuracy 95.78 %\n",
            "Epoch 00016: reducing learning rate of group 0 to 2.5000e-05.\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.101\n",
            "[ep 17][  200/  391] loss: 0.066\n",
            "[ep 17][  300/  391] loss: 0.071\n",
            "test loss 0.96776515\n",
            "test accuracy 77.80 %\n",
            "train loss 0.18516047\n",
            "train accuracy 96.89 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.184\n",
            "[ep 18][  200/  391] loss: 0.170\n",
            "[ep 18][  300/  391] loss: 0.199\n",
            "test loss 0.84489757\n",
            "test accuracy 77.26 %\n",
            "train loss 0.075343475\n",
            "train accuracy 97.11 %\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.081\n",
            "[ep 19][  200/  391] loss: 0.140\n",
            "[ep 19][  300/  391] loss: 0.085\n",
            "test loss 0.8971919\n",
            "test accuracy 77.58 %\n",
            "train loss 0.0697992\n",
            "train accuracy 97.39 %\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.233\n",
            "[ep 20][  200/  391] loss: 0.045\n",
            "[ep 20][  300/  391] loss: 0.100\n",
            "test loss 1.1177578\n",
            "test accuracy 78.03 %\n",
            "train loss 0.04882152\n",
            "train accuracy 97.60 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.057\n",
            "[ep 21][  200/  391] loss: 0.111\n",
            "[ep 21][  300/  391] loss: 0.121\n",
            "test loss 0.94903165\n",
            "test accuracy 77.69 %\n",
            "train loss 0.04270958\n",
            "train accuracy 97.56 %\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.070\n",
            "[ep 22][  200/  391] loss: 0.033\n",
            "[ep 22][  300/  391] loss: 0.123\n",
            "test loss 1.3717194\n",
            "test accuracy 77.67 %\n",
            "train loss 0.12671652\n",
            "train accuracy 97.62 %\n",
            "Epoch 00022: reducing learning rate of group 0 to 1.2500e-05.\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.109\n",
            "[ep 23][  200/  391] loss: 0.037\n",
            "[ep 23][  300/  391] loss: 0.090\n",
            "test loss 1.0150936\n",
            "test accuracy 78.12 %\n",
            "train loss 0.045949575\n",
            "train accuracy 98.16 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.032\n",
            "[ep 24][  200/  391] loss: 0.063\n",
            "[ep 24][  300/  391] loss: 0.019\n",
            "test loss 0.8936721\n",
            "test accuracy 78.03 %\n",
            "train loss 0.14402142\n",
            "train accuracy 98.25 %\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.083\n",
            "[ep 25][  200/  391] loss: 0.059\n",
            "[ep 25][  300/  391] loss: 0.186\n",
            "test loss 0.87933\n",
            "test accuracy 78.47 %\n",
            "train loss 0.062799595\n",
            "train accuracy 98.29 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.052\n",
            "[ep 26][  200/  391] loss: 0.087\n",
            "[ep 26][  300/  391] loss: 0.078\n",
            "test loss 0.72282493\n",
            "test accuracy 78.30 %\n",
            "train loss 0.13229993\n",
            "train accuracy 98.27 %\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.078\n",
            "[ep 27][  200/  391] loss: 0.074\n",
            "[ep 27][  300/  391] loss: 0.053\n",
            "test loss 0.78901464\n",
            "test accuracy 78.25 %\n",
            "train loss 0.07882175\n",
            "train accuracy 98.38 %\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.029\n",
            "[ep 28][  200/  391] loss: 0.066\n",
            "[ep 28][  300/  391] loss: 0.052\n",
            "test loss 0.65707254\n",
            "test accuracy 78.47 %\n",
            "train loss 0.102087185\n",
            "train accuracy 98.39 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.116\n",
            "[ep 29][  200/  391] loss: 0.058\n",
            "[ep 29][  300/  391] loss: 0.035\n",
            "test loss 0.8527315\n",
            "test accuracy 78.27 %\n",
            "train loss 0.014072184\n",
            "train accuracy 98.45 %\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.051\n",
            "[ep 30][  200/  391] loss: 0.054\n",
            "[ep 30][  300/  391] loss: 0.061\n",
            "test loss 0.81505215\n",
            "test accuracy 78.18 %\n",
            "train loss 0.03764353\n",
            "train accuracy 98.51 %\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.048\n",
            "[ep 31][  200/  391] loss: 0.024\n",
            "[ep 31][  300/  391] loss: 0.035\n",
            "test loss 1.1042719\n",
            "test accuracy 78.21 %\n",
            "train loss 0.12115953\n",
            "train accuracy 98.58 %\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.026\n",
            "[ep 32][  200/  391] loss: 0.050\n",
            "[ep 32][  300/  391] loss: 0.033\n",
            "test loss 1.059875\n",
            "test accuracy 78.38 %\n",
            "train loss 0.08589888\n",
            "train accuracy 98.59 %\n",
            "Epoch 00032: reducing learning rate of group 0 to 6.2500e-06.\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.077\n",
            "[ep 33][  200/  391] loss: 0.035\n",
            "[ep 33][  300/  391] loss: 0.094\n",
            "test loss 1.0008504\n",
            "test accuracy 78.59 %\n",
            "train loss 0.031793274\n",
            "train accuracy 98.79 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.039\n",
            "[ep 34][  200/  391] loss: 0.025\n",
            "[ep 34][  300/  391] loss: 0.065\n",
            "test loss 0.979991\n",
            "test accuracy 78.55 %\n",
            "train loss 0.08634691\n",
            "train accuracy 98.81 %\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.050\n",
            "[ep 35][  200/  391] loss: 0.046\n",
            "[ep 35][  300/  391] loss: 0.048\n",
            "test loss 0.9486506\n",
            "test accuracy 78.67 %\n",
            "train loss 0.020413762\n",
            "train accuracy 98.85 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.033\n",
            "[ep 36][  200/  391] loss: 0.009\n",
            "[ep 36][  300/  391] loss: 0.101\n",
            "test loss 0.9567665\n",
            "test accuracy 78.66 %\n",
            "train loss 0.032862954\n",
            "train accuracy 98.87 %\n",
            "Epoch 00036: reducing learning rate of group 0 to 3.1250e-06.\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.006\n",
            "[ep 37][  200/  391] loss: 0.055\n",
            "[ep 37][  300/  391] loss: 0.030\n",
            "test loss 0.98409075\n",
            "test accuracy 78.52 %\n",
            "train loss 0.040764727\n",
            "train accuracy 98.92 %\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.030\n",
            "[ep 38][  200/  391] loss: 0.011\n",
            "[ep 38][  300/  391] loss: 0.026\n",
            "test loss 0.94202465\n",
            "test accuracy 78.71 %\n",
            "train loss 0.059095103\n",
            "train accuracy 98.94 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.044\n",
            "[ep 39][  200/  391] loss: 0.037\n",
            "[ep 39][  300/  391] loss: 0.050\n",
            "test loss 0.89796925\n",
            "test accuracy 78.74 %\n",
            "train loss 0.16549549\n",
            "train accuracy 98.96 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.024\n",
            "[ep 40][  200/  391] loss: 0.022\n",
            "[ep 40][  300/  391] loss: 0.045\n",
            "test loss 0.8547404\n",
            "test accuracy 78.53 %\n",
            "train loss 0.029513454\n",
            "train accuracy 99.03 %\n",
            "Epoch 00040: reducing learning rate of group 0 to 1.5625e-06.\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.040\n",
            "[ep 41][  200/  391] loss: 0.033\n",
            "[ep 41][  300/  391] loss: 0.114\n",
            "test loss 0.86664385\n",
            "test accuracy 78.58 %\n",
            "train loss 0.015495072\n",
            "train accuracy 98.92 %\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.029\n",
            "[ep 42][  200/  391] loss: 0.143\n",
            "[ep 42][  300/  391] loss: 0.077\n",
            "test loss 0.87022656\n",
            "test accuracy 78.63 %\n",
            "train loss 0.010521625\n",
            "train accuracy 99.02 %\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.012\n",
            "[ep 43][  200/  391] loss: 0.009\n",
            "[ep 43][  300/  391] loss: 0.011\n",
            "test loss 0.84288573\n",
            "test accuracy 78.73 %\n",
            "train loss 0.031976465\n",
            "train accuracy 99.07 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.006\n",
            "[ep 44][  200/  391] loss: 0.018\n",
            "[ep 44][  300/  391] loss: 0.054\n",
            "test loss 0.8398794\n",
            "test accuracy 78.71 %\n",
            "train loss 0.028845271\n",
            "train accuracy 99.05 %\n",
            "Epoch 00044: reducing learning rate of group 0 to 7.8125e-07.\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.025\n",
            "[ep 45][  200/  391] loss: 0.065\n",
            "[ep 45][  300/  391] loss: 0.029\n",
            "test loss 0.8432805\n",
            "test accuracy 78.84 %\n",
            "train loss 0.0834813\n",
            "train accuracy 98.99 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.008\n",
            "[ep 46][  200/  391] loss: 0.025\n",
            "[ep 46][  300/  391] loss: 0.016\n",
            "test loss 0.851047\n",
            "test accuracy 78.72 %\n",
            "train loss 0.018470876\n",
            "train accuracy 99.12 %\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.031\n",
            "[ep 47][  200/  391] loss: 0.049\n",
            "[ep 47][  300/  391] loss: 0.047\n",
            "test loss 0.8577912\n",
            "test accuracy 78.80 %\n",
            "train loss 0.060689468\n",
            "train accuracy 99.00 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.014\n",
            "[ep 48][  200/  391] loss: 0.020\n",
            "[ep 48][  300/  391] loss: 0.030\n",
            "test loss 0.8472988\n",
            "test accuracy 78.71 %\n",
            "train loss 0.057977747\n",
            "train accuracy 98.98 %\n",
            "Epoch 00048: reducing learning rate of group 0 to 3.9063e-07.\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.012\n",
            "[ep 49][  200/  391] loss: 0.031\n",
            "[ep 49][  300/  391] loss: 0.041\n",
            "test loss 0.846781\n",
            "test accuracy 78.74 %\n",
            "train loss 0.19918774\n",
            "train accuracy 99.01 %\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.078\n",
            "[ep 50][  200/  391] loss: 0.072\n",
            "[ep 50][  300/  391] loss: 0.016\n",
            "test loss 0.850455\n",
            "test accuracy 78.76 %\n",
            "train loss 0.053431403\n",
            "train accuracy 99.02 %\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(2048, num_classes)\n",
        "#print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet50_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet50 = model_module(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet50\",stats_resnet50) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "import torch\n",
        "from torch.optim._multi_tensor import SGD\n",
        "\n",
        "__all__ = [\"SAMSGD\"]\n",
        "\n",
        "\n",
        "class SAMSGD(SGD):\n",
        "    \"\"\" SGD wrapped with Sharp-Aware Minimization\n",
        "    Args:\n",
        "        params: tensors to be optimized\n",
        "        lr: learning rate\n",
        "        momentum: momentum factor\n",
        "        dampening: damping factor\n",
        "        weight_decay: weight decay factor\n",
        "        nesterov: enables Nesterov momentum\n",
        "        rho: neighborhood size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 params: Iterable[torch.Tensor],\n",
        "                 lr: float,\n",
        "                 momentum: float = 0,\n",
        "                 dampening: float = 0,\n",
        "                 weight_decay: float = 0,\n",
        "                 nesterov: bool = False,\n",
        "                 rho: float = 0.05,\n",
        "                 ):\n",
        "        if rho <= 0:\n",
        "            raise ValueError(f\"Invalid neighborhood size: {rho}\")\n",
        "        super().__init__(params, lr, momentum, dampening, weight_decay, nesterov)\n",
        "        # todo: generalize this\n",
        "        if len(self.param_groups) > 1:\n",
        "            raise ValueError(\"Not supported\")\n",
        "        self.param_groups[0][\"rho\"] = rho\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self,\n",
        "             closure\n",
        "             ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            closure: A closure that reevaluates the model and returns the loss.\n",
        "        Returns: the loss value evaluated on the original point\n",
        "        \"\"\"\n",
        "        closure = torch.enable_grad()(closure)\n",
        "        loss = closure().detach()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            grads = []\n",
        "            params_with_grads = []\n",
        "\n",
        "            rho = group['rho']\n",
        "            # update internal_optim's learning rate\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    # without clone().detach(), p.grad will be zeroed by closure()\n",
        "                    grads.append(p.grad.clone().detach())\n",
        "                    params_with_grads.append(p)\n",
        "            device = grads[0].device\n",
        "\n",
        "            # compute \\hat{\\epsilon}=\\rho/\\norm{g}\\|g\\|\n",
        "            grad_norm = torch.stack([g.detach().norm(2).to(device) for g in grads]).norm(2)\n",
        "            epsilon = grads  # alias for readability\n",
        "            torch._foreach_mul_(epsilon, rho / grad_norm)\n",
        "\n",
        "            # virtual step toward \\epsilon\n",
        "            torch._foreach_add_(params_with_grads, epsilon)\n",
        "            # compute g=\\nabla_w L_B(w)|_{w+\\hat{\\epsilon}}\n",
        "            closure()\n",
        "            # virtual step back to the original point\n",
        "            torch._foreach_sub_(params_with_grads, epsilon)\n",
        "\n",
        "        super().step()\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_module_SAM(model, trainloader, testloader):\n",
        "\n",
        "  start = time.time()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "  optimizer = SAMSGD(model.parameters(), lr=1e-1, rho=0.05)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-8, verbose=True)\n",
        "  \n",
        "  total_epoch = 200\n",
        "  print_per_iteration = 100\n",
        "\n",
        "  train_acc=[]\n",
        "  train_loss=[]\n",
        "  test_acc=[]\n",
        "  test_loss=[]\n",
        "\n",
        "  min_acc=0\n",
        "\n",
        "  for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          # zero the parameter gradients\n",
        "          def closure():\n",
        "            optimizer.zero_grad()\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "          \n",
        "          loss = optimizer.step(closure)\n",
        "          \n",
        "          # print statistics\n",
        "          if (i+1) % print_per_iteration == 0:  \n",
        "              print(f'[ep {epoch + 1}][{i + 1:5d}/{len(trainloader):5d}] loss: {loss.item():.3f}')\n",
        "\n",
        "      # Test acc,loss in epoch\n",
        "      # fixed testing process\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "      with torch.no_grad():\n",
        "          for data in testloader:\n",
        "              images, labels = data\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              # calculate outputs by running images through the network\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              # the class with the highest energy is what we choose as prediction\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      test_acc.append(100 * correct / total)\n",
        "      test_loss.append(loss.cpu().numpy())\n",
        "      print('test loss', test_loss[-1])\n",
        "      print(f'test accuracy {test_acc[-1]:.2f} %')\n",
        "\n",
        "      # Train acc,loss in epoch\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "          for data in trainloader:\n",
        "              images, labels = data\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              # calculate outputs by running images through the network\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "              # the class with the highest energy is what we choose as prediction\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      train_acc.append(100 * correct / total)\n",
        "      train_loss.append(loss.cpu().numpy())\n",
        "      print('train loss', train_loss[-1])\n",
        "      print(f'train accuracy {train_acc[-1]:.2f} %')\n",
        "\n",
        "      scheduler.step(test_loss[-1])\n",
        "      \n",
        "      if min_acc<test_acc[-1]:\n",
        "        min_acc = test_acc[-1]\n",
        "        torch.save(model, save_path)\n",
        "        print(\"model saved !\")\n",
        "      \n",
        "      print(\"--------------------------------------------------\")\n",
        "\n",
        "  end = time.time()\n",
        "  cost_time = end-start\n",
        "  return [cost_time, train_acc, train_loss, test_acc, test_loss]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 2.677\n",
            "[ep 1][  200/  391] loss: 2.298\n",
            "[ep 1][  300/  391] loss: 2.013\n",
            "test loss 2.0676746\n",
            "test accuracy 54.40 %\n",
            "train loss 1.5310919\n",
            "train accuracy 52.14 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.568\n",
            "[ep 2][  200/  391] loss: 1.316\n",
            "[ep 2][  300/  391] loss: 1.320\n",
            "test loss 1.7512313\n",
            "test accuracy 63.13 %\n",
            "train loss 1.2681013\n",
            "train accuracy 63.86 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.256\n",
            "[ep 3][  200/  391] loss: 1.179\n",
            "[ep 3][  300/  391] loss: 1.257\n",
            "test loss 1.1630785\n",
            "test accuracy 67.15 %\n",
            "train loss 1.0565994\n",
            "train accuracy 69.44 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.946\n",
            "[ep 4][  200/  391] loss: 0.901\n",
            "[ep 4][  300/  391] loss: 1.121\n",
            "test loss 0.87678754\n",
            "test accuracy 70.13 %\n",
            "train loss 0.91306365\n",
            "train accuracy 76.32 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.626\n",
            "[ep 5][  200/  391] loss: 0.850\n",
            "[ep 5][  300/  391] loss: 1.026\n",
            "test loss 1.1247241\n",
            "test accuracy 70.69 %\n",
            "train loss 0.9961073\n",
            "train accuracy 78.46 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.649\n",
            "[ep 6][  200/  391] loss: 0.701\n",
            "[ep 6][  300/  391] loss: 0.602\n",
            "test loss 0.6750945\n",
            "test accuracy 72.48 %\n",
            "train loss 0.64263386\n",
            "train accuracy 82.36 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.661\n",
            "[ep 7][  200/  391] loss: 0.649\n",
            "[ep 7][  300/  391] loss: 0.740\n",
            "test loss 0.7364001\n",
            "test accuracy 72.48 %\n",
            "train loss 0.5835311\n",
            "train accuracy 83.71 %\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.574\n",
            "[ep 8][  200/  391] loss: 0.588\n",
            "[ep 8][  300/  391] loss: 0.698\n",
            "test loss 0.7928464\n",
            "test accuracy 73.12 %\n",
            "train loss 0.4338315\n",
            "train accuracy 86.54 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.361\n",
            "[ep 9][  200/  391] loss: 0.467\n",
            "[ep 9][  300/  391] loss: 0.376\n",
            "test loss 0.55372596\n",
            "test accuracy 73.38 %\n",
            "train loss 0.33875325\n",
            "train accuracy 88.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.521\n",
            "[ep 10][  200/  391] loss: 0.403\n",
            "[ep 10][  300/  391] loss: 0.400\n",
            "test loss 0.6887765\n",
            "test accuracy 72.46 %\n",
            "train loss 0.40790886\n",
            "train accuracy 89.02 %\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.323\n",
            "[ep 11][  200/  391] loss: 0.330\n",
            "[ep 11][  300/  391] loss: 0.358\n",
            "test loss 0.5728709\n",
            "test accuracy 73.08 %\n",
            "train loss 0.21080191\n",
            "train accuracy 90.24 %\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.394\n",
            "[ep 12][  200/  391] loss: 0.300\n",
            "[ep 12][  300/  391] loss: 0.358\n",
            "test loss 0.41770768\n",
            "test accuracy 73.62 %\n",
            "train loss 0.38446608\n",
            "train accuracy 91.20 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.280\n",
            "[ep 13][  200/  391] loss: 0.322\n",
            "[ep 13][  300/  391] loss: 0.207\n",
            "test loss 0.50163907\n",
            "test accuracy 74.20 %\n",
            "train loss 0.30593774\n",
            "train accuracy 92.75 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.270\n",
            "[ep 14][  200/  391] loss: 0.167\n",
            "[ep 14][  300/  391] loss: 0.236\n",
            "test loss 0.63264686\n",
            "test accuracy 74.12 %\n",
            "train loss 0.20472372\n",
            "train accuracy 93.21 %\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.301\n",
            "[ep 15][  200/  391] loss: 0.254\n",
            "[ep 15][  300/  391] loss: 0.166\n",
            "test loss 0.82504636\n",
            "test accuracy 74.21 %\n",
            "train loss 0.33847538\n",
            "train accuracy 93.98 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.204\n",
            "[ep 16][  200/  391] loss: 0.249\n",
            "[ep 16][  300/  391] loss: 0.160\n",
            "test loss 0.57202846\n",
            "test accuracy 74.60 %\n",
            "train loss 0.1652045\n",
            "train accuracy 94.53 %\n",
            "Epoch 00016: reducing learning rate of group 0 to 5.0000e-02.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.136\n",
            "[ep 17][  200/  391] loss: 0.182\n",
            "[ep 17][  300/  391] loss: 0.132\n",
            "test loss 0.46819305\n",
            "test accuracy 76.39 %\n",
            "train loss 0.08663776\n",
            "train accuracy 96.88 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.131\n",
            "[ep 18][  200/  391] loss: 0.106\n",
            "[ep 18][  300/  391] loss: 0.153\n",
            "test loss 0.7508415\n",
            "test accuracy 76.26 %\n",
            "train loss 0.17261109\n",
            "train accuracy 97.16 %\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.135\n",
            "[ep 19][  200/  391] loss: 0.142\n",
            "[ep 19][  300/  391] loss: 0.127\n",
            "test loss 0.67277646\n",
            "test accuracy 76.33 %\n",
            "train loss 0.13680127\n",
            "train accuracy 97.44 %\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.169\n",
            "[ep 20][  200/  391] loss: 0.114\n",
            "[ep 20][  300/  391] loss: 0.069\n",
            "test loss 0.46581125\n",
            "test accuracy 76.46 %\n",
            "train loss 0.04783811\n",
            "train accuracy 97.66 %\n",
            "Epoch 00020: reducing learning rate of group 0 to 2.5000e-02.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.105\n",
            "[ep 21][  200/  391] loss: 0.128\n",
            "[ep 21][  300/  391] loss: 0.097\n",
            "test loss 0.49152517\n",
            "test accuracy 77.09 %\n",
            "train loss 0.14638169\n",
            "train accuracy 97.98 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.069\n",
            "[ep 22][  200/  391] loss: 0.160\n",
            "[ep 22][  300/  391] loss: 0.053\n",
            "test loss 0.51536304\n",
            "test accuracy 77.22 %\n",
            "train loss 0.0772504\n",
            "train accuracy 98.16 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.067\n",
            "[ep 23][  200/  391] loss: 0.080\n",
            "[ep 23][  300/  391] loss: 0.075\n",
            "test loss 0.7182505\n",
            "test accuracy 76.96 %\n",
            "train loss 0.050234992\n",
            "train accuracy 98.22 %\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.040\n",
            "[ep 24][  200/  391] loss: 0.064\n",
            "[ep 24][  300/  391] loss: 0.080\n",
            "test loss 0.5449904\n",
            "test accuracy 77.09 %\n",
            "train loss 0.08882368\n",
            "train accuracy 98.38 %\n",
            "Epoch 00024: reducing learning rate of group 0 to 1.2500e-02.\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.099\n",
            "[ep 25][  200/  391] loss: 0.064\n",
            "[ep 25][  300/  391] loss: 0.107\n",
            "test loss 0.63171834\n",
            "test accuracy 77.16 %\n",
            "train loss 0.07468963\n",
            "train accuracy 98.53 %\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.102\n",
            "[ep 26][  200/  391] loss: 0.061\n",
            "[ep 26][  300/  391] loss: 0.040\n",
            "test loss 0.5753255\n",
            "test accuracy 77.16 %\n",
            "train loss 0.10636385\n",
            "train accuracy 98.53 %\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.059\n",
            "[ep 27][  200/  391] loss: 0.089\n",
            "[ep 27][  300/  391] loss: 0.065\n",
            "test loss 0.5995269\n",
            "test accuracy 77.22 %\n",
            "train loss 0.13033052\n",
            "train accuracy 98.55 %\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.046\n",
            "[ep 28][  200/  391] loss: 0.105\n",
            "[ep 28][  300/  391] loss: 0.065\n",
            "test loss 0.5809677\n",
            "test accuracy 77.29 %\n",
            "train loss 0.027366092\n",
            "train accuracy 98.67 %\n",
            "Epoch 00028: reducing learning rate of group 0 to 6.2500e-03.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.051\n",
            "[ep 29][  200/  391] loss: 0.071\n",
            "[ep 29][  300/  391] loss: 0.085\n",
            "test loss 0.6253813\n",
            "test accuracy 77.42 %\n",
            "train loss 0.06532938\n",
            "train accuracy 98.61 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.046\n",
            "[ep 30][  200/  391] loss: 0.042\n",
            "[ep 30][  300/  391] loss: 0.087\n",
            "test loss 0.6058613\n",
            "test accuracy 77.51 %\n",
            "train loss 0.04069514\n",
            "train accuracy 98.73 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.060\n",
            "[ep 31][  200/  391] loss: 0.083\n",
            "[ep 31][  300/  391] loss: 0.083\n",
            "test loss 0.5854709\n",
            "test accuracy 77.39 %\n",
            "train loss 0.036731306\n",
            "train accuracy 98.76 %\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.090\n",
            "[ep 32][  200/  391] loss: 0.105\n",
            "[ep 32][  300/  391] loss: 0.048\n",
            "test loss 0.59370774\n",
            "test accuracy 77.32 %\n",
            "train loss 0.054548033\n",
            "train accuracy 98.85 %\n",
            "Epoch 00032: reducing learning rate of group 0 to 3.1250e-03.\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.062\n",
            "[ep 33][  200/  391] loss: 0.048\n",
            "[ep 33][  300/  391] loss: 0.035\n",
            "test loss 0.5855452\n",
            "test accuracy 77.43 %\n",
            "train loss 0.040148366\n",
            "train accuracy 98.82 %\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.067\n",
            "[ep 34][  200/  391] loss: 0.037\n",
            "[ep 34][  300/  391] loss: 0.065\n",
            "test loss 0.57874084\n",
            "test accuracy 77.41 %\n",
            "train loss 0.030449469\n",
            "train accuracy 98.87 %\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.066\n",
            "[ep 35][  200/  391] loss: 0.059\n",
            "[ep 35][  300/  391] loss: 0.098\n",
            "test loss 0.5965087\n",
            "test accuracy 77.52 %\n",
            "train loss 0.061525565\n",
            "train accuracy 98.78 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.050\n",
            "[ep 36][  200/  391] loss: 0.067\n",
            "[ep 36][  300/  391] loss: 0.069\n",
            "test loss 0.62288374\n",
            "test accuracy 77.74 %\n",
            "train loss 0.12241417\n",
            "train accuracy 98.82 %\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.5625e-03.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.069\n",
            "[ep 37][  200/  391] loss: 0.028\n",
            "[ep 37][  300/  391] loss: 0.068\n",
            "test loss 0.634587\n",
            "test accuracy 77.77 %\n",
            "train loss 0.13005021\n",
            "train accuracy 98.76 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.037\n",
            "[ep 38][  200/  391] loss: 0.094\n",
            "[ep 38][  300/  391] loss: 0.057\n",
            "test loss 0.62897813\n",
            "test accuracy 77.80 %\n",
            "train loss 0.035616495\n",
            "train accuracy 98.80 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.065\n",
            "[ep 39][  200/  391] loss: 0.055\n",
            "[ep 39][  300/  391] loss: 0.036\n",
            "test loss 0.6283429\n",
            "test accuracy 77.76 %\n",
            "train loss 0.10039576\n",
            "train accuracy 98.81 %\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.063\n",
            "[ep 40][  200/  391] loss: 0.061\n",
            "[ep 40][  300/  391] loss: 0.043\n",
            "test loss 0.6265923\n",
            "test accuracy 77.71 %\n",
            "train loss 0.0610789\n",
            "train accuracy 98.77 %\n",
            "Epoch 00040: reducing learning rate of group 0 to 7.8125e-04.\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.029\n",
            "[ep 41][  200/  391] loss: 0.060\n",
            "[ep 41][  300/  391] loss: 0.085\n",
            "test loss 0.62298846\n",
            "test accuracy 77.67 %\n",
            "train loss 0.05787732\n",
            "train accuracy 98.84 %\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.058\n",
            "[ep 42][  200/  391] loss: 0.050\n",
            "[ep 42][  300/  391] loss: 0.036\n",
            "test loss 0.6220638\n",
            "test accuracy 77.70 %\n",
            "train loss 0.1369771\n",
            "train accuracy 98.87 %\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.027\n",
            "[ep 43][  200/  391] loss: 0.036\n",
            "[ep 43][  300/  391] loss: 0.062\n",
            "test loss 0.6281044\n",
            "test accuracy 77.64 %\n",
            "train loss 0.028083807\n",
            "train accuracy 98.87 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.051\n",
            "[ep 44][  200/  391] loss: 0.042\n",
            "[ep 44][  300/  391] loss: 0.099\n",
            "test loss 0.62897015\n",
            "test accuracy 77.74 %\n",
            "train loss 0.07516728\n",
            "train accuracy 98.84 %\n",
            "Epoch 00044: reducing learning rate of group 0 to 3.9063e-04.\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.076\n",
            "[ep 45][  200/  391] loss: 0.037\n",
            "[ep 45][  300/  391] loss: 0.064\n",
            "test loss 0.6256004\n",
            "test accuracy 77.71 %\n",
            "train loss 0.079739824\n",
            "train accuracy 98.85 %\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.084\n",
            "[ep 46][  200/  391] loss: 0.062\n",
            "[ep 46][  300/  391] loss: 0.038\n",
            "test loss 0.62080526\n",
            "test accuracy 77.74 %\n",
            "train loss 0.025627341\n",
            "train accuracy 98.89 %\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.039\n",
            "[ep 47][  200/  391] loss: 0.054\n",
            "[ep 47][  300/  391] loss: 0.065\n",
            "test loss 0.6231505\n",
            "test accuracy 77.74 %\n",
            "train loss 0.028442511\n",
            "train accuracy 98.84 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.063\n",
            "[ep 48][  200/  391] loss: 0.062\n",
            "[ep 48][  300/  391] loss: 0.040\n",
            "test loss 0.62348276\n",
            "test accuracy 77.71 %\n",
            "train loss 0.030212035\n",
            "train accuracy 98.86 %\n",
            "Epoch 00048: reducing learning rate of group 0 to 1.9531e-04.\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.043\n",
            "[ep 49][  200/  391] loss: 0.049\n",
            "[ep 49][  300/  391] loss: 0.083\n",
            "test loss 0.62399703\n",
            "test accuracy 77.70 %\n",
            "train loss 0.061009794\n",
            "train accuracy 98.91 %\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.047\n",
            "[ep 50][  200/  391] loss: 0.057\n",
            "[ep 50][  300/  391] loss: 0.127\n",
            "test loss 0.6236383\n",
            "test accuracy 77.77 %\n",
            "train loss 0.0646065\n",
            "train accuracy 98.80 %\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(512, num_classes)\n",
        "#print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet18_SAM_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet18_SAM = model_module_SAM(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet18_SAM\",stats_resnet18_SAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 2.998\n",
            "[ep 1][  200/  391] loss: 2.279\n",
            "[ep 1][  300/  391] loss: 1.832\n",
            "test loss 1.2909801\n",
            "test accuracy 59.66 %\n",
            "train loss 1.4650767\n",
            "train accuracy 57.03 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.217\n",
            "[ep 2][  200/  391] loss: 1.581\n",
            "[ep 2][  300/  391] loss: 1.199\n",
            "test loss 1.4393035\n",
            "test accuracy 68.02 %\n",
            "train loss 1.0051525\n",
            "train accuracy 69.10 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.034\n",
            "[ep 3][  200/  391] loss: 0.906\n",
            "[ep 3][  300/  391] loss: 0.934\n",
            "test loss 0.978389\n",
            "test accuracy 72.57 %\n",
            "train loss 0.8418201\n",
            "train accuracy 76.26 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.783\n",
            "[ep 4][  200/  391] loss: 0.739\n",
            "[ep 4][  300/  391] loss: 0.929\n",
            "test loss 0.64115876\n",
            "test accuracy 75.30 %\n",
            "train loss 0.7467891\n",
            "train accuracy 81.41 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.648\n",
            "[ep 5][  200/  391] loss: 0.614\n",
            "[ep 5][  300/  391] loss: 0.658\n",
            "test loss 0.8255948\n",
            "test accuracy 76.06 %\n",
            "train loss 0.4689578\n",
            "train accuracy 84.76 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.511\n",
            "[ep 6][  200/  391] loss: 0.598\n",
            "[ep 6][  300/  391] loss: 0.575\n",
            "test loss 0.56120104\n",
            "test accuracy 76.95 %\n",
            "train loss 0.46453872\n",
            "train accuracy 86.76 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.446\n",
            "[ep 7][  200/  391] loss: 0.453\n",
            "[ep 7][  300/  391] loss: 0.723\n",
            "test loss 0.6830842\n",
            "test accuracy 76.57 %\n",
            "train loss 0.43312636\n",
            "train accuracy 88.57 %\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.365\n",
            "[ep 8][  200/  391] loss: 0.318\n",
            "[ep 8][  300/  391] loss: 0.480\n",
            "test loss 0.65954536\n",
            "test accuracy 76.73 %\n",
            "train loss 0.34973043\n",
            "train accuracy 89.79 %\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.326\n",
            "[ep 9][  200/  391] loss: 0.275\n",
            "[ep 9][  300/  391] loss: 0.334\n",
            "test loss 0.8277007\n",
            "test accuracy 77.51 %\n",
            "train loss 0.33064532\n",
            "train accuracy 91.45 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.326\n",
            "[ep 10][  200/  391] loss: 0.235\n",
            "[ep 10][  300/  391] loss: 0.299\n",
            "test loss 0.65101385\n",
            "test accuracy 77.80 %\n",
            "train loss 0.31235883\n",
            "train accuracy 93.14 %\n",
            "Epoch 00010: reducing learning rate of group 0 to 5.0000e-02.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.211\n",
            "[ep 11][  200/  391] loss: 0.190\n",
            "[ep 11][  300/  391] loss: 0.189\n",
            "test loss 0.5859225\n",
            "test accuracy 80.30 %\n",
            "train loss 0.12691408\n",
            "train accuracy 95.95 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.124\n",
            "[ep 12][  200/  391] loss: 0.132\n",
            "[ep 12][  300/  391] loss: 0.154\n",
            "test loss 0.65960705\n",
            "test accuracy 80.26 %\n",
            "train loss 0.109864414\n",
            "train accuracy 96.47 %\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.161\n",
            "[ep 13][  200/  391] loss: 0.168\n",
            "[ep 13][  300/  391] loss: 0.117\n",
            "test loss 0.5124796\n",
            "test accuracy 80.34 %\n",
            "train loss 0.12827638\n",
            "train accuracy 96.75 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.103\n",
            "[ep 14][  200/  391] loss: 0.167\n",
            "[ep 14][  300/  391] loss: 0.178\n",
            "test loss 0.48040217\n",
            "test accuracy 80.90 %\n",
            "train loss 0.09063427\n",
            "train accuracy 97.17 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.118\n",
            "[ep 15][  200/  391] loss: 0.113\n",
            "[ep 15][  300/  391] loss: 0.105\n",
            "test loss 0.5742627\n",
            "test accuracy 80.23 %\n",
            "train loss 0.13124636\n",
            "train accuracy 97.21 %\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.125\n",
            "[ep 16][  200/  391] loss: 0.094\n",
            "[ep 16][  300/  391] loss: 0.058\n",
            "test loss 0.6450621\n",
            "test accuracy 80.59 %\n",
            "train loss 0.04619898\n",
            "train accuracy 97.63 %\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.102\n",
            "[ep 17][  200/  391] loss: 0.166\n",
            "[ep 17][  300/  391] loss: 0.142\n",
            "test loss 0.5389696\n",
            "test accuracy 80.42 %\n",
            "train loss 0.028795034\n",
            "train accuracy 97.64 %\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.101\n",
            "[ep 18][  200/  391] loss: 0.128\n",
            "[ep 18][  300/  391] loss: 0.086\n",
            "test loss 0.5641762\n",
            "test accuracy 80.66 %\n",
            "train loss 0.10329695\n",
            "train accuracy 97.97 %\n",
            "Epoch 00018: reducing learning rate of group 0 to 2.5000e-02.\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.096\n",
            "[ep 19][  200/  391] loss: 0.053\n",
            "[ep 19][  300/  391] loss: 0.052\n",
            "test loss 0.6307398\n",
            "test accuracy 81.43 %\n",
            "train loss 0.083789065\n",
            "train accuracy 98.41 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.100\n",
            "[ep 20][  200/  391] loss: 0.090\n",
            "[ep 20][  300/  391] loss: 0.088\n",
            "test loss 0.55753946\n",
            "test accuracy 81.34 %\n",
            "train loss 0.0911208\n",
            "train accuracy 98.57 %\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.046\n",
            "[ep 21][  200/  391] loss: 0.076\n",
            "[ep 21][  300/  391] loss: 0.044\n",
            "test loss 0.64984745\n",
            "test accuracy 81.50 %\n",
            "train loss 0.09707295\n",
            "train accuracy 98.59 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.045\n",
            "[ep 22][  200/  391] loss: 0.069\n",
            "[ep 22][  300/  391] loss: 0.049\n",
            "test loss 0.44184843\n",
            "test accuracy 81.39 %\n",
            "train loss 0.048587527\n",
            "train accuracy 98.66 %\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.042\n",
            "[ep 23][  200/  391] loss: 0.069\n",
            "[ep 23][  300/  391] loss: 0.043\n",
            "test loss 0.53704625\n",
            "test accuracy 81.56 %\n",
            "train loss 0.057326145\n",
            "train accuracy 98.76 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.036\n",
            "[ep 24][  200/  391] loss: 0.058\n",
            "[ep 24][  300/  391] loss: 0.054\n",
            "test loss 0.5197841\n",
            "test accuracy 81.43 %\n",
            "train loss 0.02604962\n",
            "train accuracy 98.81 %\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.106\n",
            "[ep 25][  200/  391] loss: 0.083\n",
            "[ep 25][  300/  391] loss: 0.066\n",
            "test loss 0.5005604\n",
            "test accuracy 81.62 %\n",
            "train loss 0.06263147\n",
            "train accuracy 98.86 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.073\n",
            "[ep 26][  200/  391] loss: 0.037\n",
            "[ep 26][  300/  391] loss: 0.059\n",
            "test loss 0.44672018\n",
            "test accuracy 81.52 %\n",
            "train loss 0.026543355\n",
            "train accuracy 98.93 %\n",
            "Epoch 00026: reducing learning rate of group 0 to 1.2500e-02.\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.069\n",
            "[ep 27][  200/  391] loss: 0.041\n",
            "[ep 27][  300/  391] loss: 0.048\n",
            "test loss 0.4952702\n",
            "test accuracy 81.90 %\n",
            "train loss 0.051249694\n",
            "train accuracy 99.00 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.116\n",
            "[ep 28][  200/  391] loss: 0.051\n",
            "[ep 28][  300/  391] loss: 0.104\n",
            "test loss 0.4967548\n",
            "test accuracy 81.76 %\n",
            "train loss 0.061490588\n",
            "train accuracy 99.10 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.033\n",
            "[ep 29][  200/  391] loss: 0.086\n",
            "[ep 29][  300/  391] loss: 0.018\n",
            "test loss 0.45070952\n",
            "test accuracy 81.96 %\n",
            "train loss 0.075729534\n",
            "train accuracy 99.16 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.037\n",
            "[ep 30][  200/  391] loss: 0.027\n",
            "[ep 30][  300/  391] loss: 0.075\n",
            "test loss 0.5277919\n",
            "test accuracy 82.09 %\n",
            "train loss 0.05090595\n",
            "train accuracy 99.14 %\n",
            "Epoch 00030: reducing learning rate of group 0 to 6.2500e-03.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.068\n",
            "[ep 31][  200/  391] loss: 0.034\n",
            "[ep 31][  300/  391] loss: 0.028\n",
            "test loss 0.50258374\n",
            "test accuracy 82.00 %\n",
            "train loss 0.0372502\n",
            "train accuracy 99.12 %\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.039\n",
            "[ep 32][  200/  391] loss: 0.015\n",
            "[ep 32][  300/  391] loss: 0.049\n",
            "test loss 0.5167048\n",
            "test accuracy 82.22 %\n",
            "train loss 0.05573523\n",
            "train accuracy 99.19 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.028\n",
            "[ep 33][  200/  391] loss: 0.031\n",
            "[ep 33][  300/  391] loss: 0.054\n",
            "test loss 0.5212305\n",
            "test accuracy 81.78 %\n",
            "train loss 0.02813623\n",
            "train accuracy 99.28 %\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.060\n",
            "[ep 34][  200/  391] loss: 0.041\n",
            "[ep 34][  300/  391] loss: 0.017\n",
            "test loss 0.48374137\n",
            "test accuracy 82.07 %\n",
            "train loss 0.022457661\n",
            "train accuracy 99.20 %\n",
            "Epoch 00034: reducing learning rate of group 0 to 3.1250e-03.\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.021\n",
            "[ep 35][  200/  391] loss: 0.017\n",
            "[ep 35][  300/  391] loss: 0.055\n",
            "test loss 0.4957282\n",
            "test accuracy 82.21 %\n",
            "train loss 0.10343764\n",
            "train accuracy 99.21 %\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.053\n",
            "[ep 36][  200/  391] loss: 0.044\n",
            "[ep 36][  300/  391] loss: 0.046\n",
            "test loss 0.51706696\n",
            "test accuracy 82.28 %\n",
            "train loss 0.023088802\n",
            "train accuracy 99.18 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.054\n",
            "[ep 37][  200/  391] loss: 0.023\n",
            "[ep 37][  300/  391] loss: 0.055\n",
            "test loss 0.49673846\n",
            "test accuracy 82.16 %\n",
            "train loss 0.03925848\n",
            "train accuracy 99.22 %\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.046\n",
            "[ep 38][  200/  391] loss: 0.062\n",
            "[ep 38][  300/  391] loss: 0.037\n",
            "test loss 0.4895296\n",
            "test accuracy 82.28 %\n",
            "train loss 0.0525523\n",
            "train accuracy 99.25 %\n",
            "Epoch 00038: reducing learning rate of group 0 to 1.5625e-03.\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.027\n",
            "[ep 39][  200/  391] loss: 0.029\n",
            "[ep 39][  300/  391] loss: 0.023\n",
            "test loss 0.48743048\n",
            "test accuracy 82.28 %\n",
            "train loss 0.048209462\n",
            "train accuracy 99.25 %\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.038\n",
            "[ep 40][  200/  391] loss: 0.049\n",
            "[ep 40][  300/  391] loss: 0.054\n",
            "test loss 0.48821816\n",
            "test accuracy 82.21 %\n",
            "train loss 0.03687558\n",
            "train accuracy 99.28 %\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.028\n",
            "[ep 41][  200/  391] loss: 0.036\n",
            "[ep 41][  300/  391] loss: 0.059\n",
            "test loss 0.49422953\n",
            "test accuracy 82.29 %\n",
            "train loss 0.022175008\n",
            "train accuracy 99.27 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.038\n",
            "[ep 42][  200/  391] loss: 0.075\n",
            "[ep 42][  300/  391] loss: 0.024\n",
            "test loss 0.49660262\n",
            "test accuracy 82.32 %\n",
            "train loss 0.045447607\n",
            "train accuracy 99.29 %\n",
            "Epoch 00042: reducing learning rate of group 0 to 7.8125e-04.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.094\n",
            "[ep 43][  200/  391] loss: 0.056\n",
            "[ep 43][  300/  391] loss: 0.041\n",
            "test loss 0.49570513\n",
            "test accuracy 82.36 %\n",
            "train loss 0.054119878\n",
            "train accuracy 99.23 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.060\n",
            "[ep 44][  200/  391] loss: 0.024\n",
            "[ep 44][  300/  391] loss: 0.031\n",
            "test loss 0.5031317\n",
            "test accuracy 82.35 %\n",
            "train loss 0.034070928\n",
            "train accuracy 99.24 %\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.021\n",
            "[ep 45][  200/  391] loss: 0.016\n",
            "[ep 45][  300/  391] loss: 0.085\n",
            "test loss 0.5078154\n",
            "test accuracy 82.22 %\n",
            "train loss 0.024060395\n",
            "train accuracy 99.27 %\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.057\n",
            "[ep 46][  200/  391] loss: 0.029\n",
            "[ep 46][  300/  391] loss: 0.059\n",
            "test loss 0.5079314\n",
            "test accuracy 82.29 %\n",
            "train loss 0.03557641\n",
            "train accuracy 99.31 %\n",
            "Epoch 00046: reducing learning rate of group 0 to 3.9063e-04.\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.025\n",
            "[ep 47][  200/  391] loss: 0.041\n",
            "[ep 47][  300/  391] loss: 0.065\n",
            "test loss 0.5042193\n",
            "test accuracy 82.17 %\n",
            "train loss 0.03305171\n",
            "train accuracy 99.25 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.042\n",
            "[ep 48][  200/  391] loss: 0.049\n",
            "[ep 48][  300/  391] loss: 0.045\n",
            "test loss 0.50496036\n",
            "test accuracy 82.21 %\n",
            "train loss 0.029779464\n",
            "train accuracy 99.21 %\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.033\n",
            "[ep 49][  200/  391] loss: 0.042\n",
            "[ep 49][  300/  391] loss: 0.047\n",
            "test loss 0.50759697\n",
            "test accuracy 82.18 %\n",
            "train loss 0.061889935\n",
            "train accuracy 99.21 %\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.018\n",
            "[ep 50][  200/  391] loss: 0.102\n",
            "[ep 50][  300/  391] loss: 0.017\n",
            "test loss 0.5096586\n",
            "test accuracy 82.23 %\n",
            "train loss 0.018269101\n",
            "train accuracy 99.35 %\n",
            "Epoch 00050: reducing learning rate of group 0 to 1.9531e-04.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Eclab\\anaconda3\\envs\\pytorch37\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet34(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(512, num_classes)\n",
        "#print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet34_SAM_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet34_SAM = model_module_SAM(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet34_SAM\", stats_resnet34_SAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 2.821\n",
            "[ep 1][  200/  391] loss: 1.968\n",
            "[ep 1][  300/  391] loss: 1.444\n",
            "test loss 1.3780203\n",
            "test accuracy 63.36 %\n",
            "train loss 1.5123036\n",
            "train accuracy 61.03 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.468\n",
            "[ep 2][  200/  391] loss: 1.168\n",
            "[ep 2][  300/  391] loss: 1.183\n",
            "test loss 1.2391137\n",
            "test accuracy 69.66 %\n",
            "train loss 1.0584048\n",
            "train accuracy 70.13 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 0.815\n",
            "[ep 3][  200/  391] loss: 0.906\n",
            "[ep 3][  300/  391] loss: 1.004\n",
            "test loss 0.7996159\n",
            "test accuracy 73.43 %\n",
            "train loss 0.6597194\n",
            "train accuracy 77.89 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.684\n",
            "[ep 4][  200/  391] loss: 0.668\n",
            "[ep 4][  300/  391] loss: 0.855\n",
            "test loss 0.7603228\n",
            "test accuracy 75.48 %\n",
            "train loss 0.46425086\n",
            "train accuracy 81.34 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.547\n",
            "[ep 5][  200/  391] loss: 0.553\n",
            "[ep 5][  300/  391] loss: 0.810\n",
            "test loss 0.7554412\n",
            "test accuracy 77.59 %\n",
            "train loss 0.40651226\n",
            "train accuracy 85.39 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.605\n",
            "[ep 6][  200/  391] loss: 0.487\n",
            "[ep 6][  300/  391] loss: 0.462\n",
            "test loss 0.842456\n",
            "test accuracy 76.93 %\n",
            "train loss 0.48633194\n",
            "train accuracy 86.13 %\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.488\n",
            "[ep 7][  200/  391] loss: 0.624\n",
            "[ep 7][  300/  391] loss: 0.406\n",
            "test loss 1.083873\n",
            "test accuracy 78.31 %\n",
            "train loss 0.34098062\n",
            "train accuracy 88.79 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.358\n",
            "[ep 8][  200/  391] loss: 0.409\n",
            "[ep 8][  300/  391] loss: 0.410\n",
            "test loss 0.91485244\n",
            "test accuracy 78.06 %\n",
            "train loss 0.37883586\n",
            "train accuracy 90.91 %\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.316\n",
            "[ep 9][  200/  391] loss: 0.313\n",
            "[ep 9][  300/  391] loss: 0.329\n",
            "test loss 0.787166\n",
            "test accuracy 77.83 %\n",
            "train loss 0.40389687\n",
            "train accuracy 90.80 %\n",
            "Epoch 00009: reducing learning rate of group 0 to 5.0000e-02.\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.204\n",
            "[ep 10][  200/  391] loss: 0.243\n",
            "[ep 10][  300/  391] loss: 0.168\n",
            "test loss 0.71494466\n",
            "test accuracy 81.27 %\n",
            "train loss 0.17901388\n",
            "train accuracy 95.49 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.171\n",
            "[ep 11][  200/  391] loss: 0.197\n",
            "[ep 11][  300/  391] loss: 0.126\n",
            "test loss 0.7615364\n",
            "test accuracy 81.74 %\n",
            "train loss 0.13246632\n",
            "train accuracy 96.38 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.177\n",
            "[ep 12][  200/  391] loss: 0.185\n",
            "[ep 12][  300/  391] loss: 0.147\n",
            "test loss 0.8251333\n",
            "test accuracy 81.47 %\n",
            "train loss 0.14136991\n",
            "train accuracy 96.82 %\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.109\n",
            "[ep 13][  200/  391] loss: 0.163\n",
            "[ep 13][  300/  391] loss: 0.111\n",
            "test loss 0.70049834\n",
            "test accuracy 81.72 %\n",
            "train loss 0.12371274\n",
            "train accuracy 97.04 %\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.131\n",
            "[ep 14][  200/  391] loss: 0.081\n",
            "[ep 14][  300/  391] loss: 0.142\n",
            "test loss 0.4235118\n",
            "test accuracy 81.64 %\n",
            "train loss 0.15497819\n",
            "train accuracy 97.25 %\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.098\n",
            "[ep 15][  200/  391] loss: 0.212\n",
            "[ep 15][  300/  391] loss: 0.108\n",
            "test loss 0.8276433\n",
            "test accuracy 81.65 %\n",
            "train loss 0.111883655\n",
            "train accuracy 97.54 %\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.064\n",
            "[ep 16][  200/  391] loss: 0.101\n",
            "[ep 16][  300/  391] loss: 0.074\n",
            "test loss 0.70282865\n",
            "test accuracy 81.50 %\n",
            "train loss 0.11834737\n",
            "train accuracy 97.68 %\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.080\n",
            "[ep 17][  200/  391] loss: 0.143\n",
            "[ep 17][  300/  391] loss: 0.085\n",
            "test loss 0.68608737\n",
            "test accuracy 81.55 %\n",
            "train loss 0.0763436\n",
            "train accuracy 97.72 %\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.044\n",
            "[ep 18][  200/  391] loss: 0.075\n",
            "[ep 18][  300/  391] loss: 0.152\n",
            "test loss 0.6890008\n",
            "test accuracy 82.04 %\n",
            "train loss 0.0934806\n",
            "train accuracy 98.00 %\n",
            "Epoch 00018: reducing learning rate of group 0 to 2.5000e-02.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.070\n",
            "[ep 19][  200/  391] loss: 0.080\n",
            "[ep 19][  300/  391] loss: 0.058\n",
            "test loss 0.72131205\n",
            "test accuracy 82.21 %\n",
            "train loss 0.0636007\n",
            "train accuracy 98.51 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.071\n",
            "[ep 20][  200/  391] loss: 0.037\n",
            "[ep 20][  300/  391] loss: 0.035\n",
            "test loss 0.5949049\n",
            "test accuracy 82.55 %\n",
            "train loss 0.06915656\n",
            "train accuracy 98.62 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.071\n",
            "[ep 21][  200/  391] loss: 0.059\n",
            "[ep 21][  300/  391] loss: 0.046\n",
            "test loss 0.65061355\n",
            "test accuracy 82.67 %\n",
            "train loss 0.08712874\n",
            "train accuracy 98.84 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.033\n",
            "[ep 22][  200/  391] loss: 0.090\n",
            "[ep 22][  300/  391] loss: 0.048\n",
            "test loss 0.7068471\n",
            "test accuracy 82.67 %\n",
            "train loss 0.10122832\n",
            "train accuracy 98.90 %\n",
            "Epoch 00022: reducing learning rate of group 0 to 1.2500e-02.\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.038\n",
            "[ep 23][  200/  391] loss: 0.044\n",
            "[ep 23][  300/  391] loss: 0.037\n",
            "test loss 0.6990861\n",
            "test accuracy 82.63 %\n",
            "train loss 0.07919987\n",
            "train accuracy 98.93 %\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.066\n",
            "[ep 24][  200/  391] loss: 0.033\n",
            "[ep 24][  300/  391] loss: 0.081\n",
            "test loss 0.73629737\n",
            "test accuracy 82.89 %\n",
            "train loss 0.06246118\n",
            "train accuracy 99.03 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.034\n",
            "[ep 25][  200/  391] loss: 0.035\n",
            "[ep 25][  300/  391] loss: 0.023\n",
            "test loss 0.7191412\n",
            "test accuracy 82.98 %\n",
            "train loss 0.021060655\n",
            "train accuracy 99.09 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.031\n",
            "[ep 26][  200/  391] loss: 0.012\n",
            "[ep 26][  300/  391] loss: 0.027\n",
            "test loss 0.76567405\n",
            "test accuracy 82.66 %\n",
            "train loss 0.07096156\n",
            "train accuracy 99.18 %\n",
            "Epoch 00026: reducing learning rate of group 0 to 6.2500e-03.\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.062\n",
            "[ep 27][  200/  391] loss: 0.027\n",
            "[ep 27][  300/  391] loss: 0.070\n",
            "test loss 0.7223584\n",
            "test accuracy 82.91 %\n",
            "train loss 0.07193882\n",
            "train accuracy 99.08 %\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.037\n",
            "[ep 28][  200/  391] loss: 0.044\n",
            "[ep 28][  300/  391] loss: 0.046\n",
            "test loss 0.7240844\n",
            "test accuracy 82.93 %\n",
            "train loss 0.021237168\n",
            "train accuracy 99.10 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.027\n",
            "[ep 29][  200/  391] loss: 0.064\n",
            "[ep 29][  300/  391] loss: 0.041\n",
            "test loss 0.7404586\n",
            "test accuracy 82.91 %\n",
            "train loss 0.032758277\n",
            "train accuracy 99.16 %\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.051\n",
            "[ep 30][  200/  391] loss: 0.027\n",
            "[ep 30][  300/  391] loss: 0.020\n",
            "test loss 0.70566964\n",
            "test accuracy 82.93 %\n",
            "train loss 0.12545434\n",
            "train accuracy 99.23 %\n",
            "Epoch 00030: reducing learning rate of group 0 to 3.1250e-03.\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.036\n",
            "[ep 31][  200/  391] loss: 0.034\n",
            "[ep 31][  300/  391] loss: 0.024\n",
            "test loss 0.7328207\n",
            "test accuracy 82.97 %\n",
            "train loss 0.02230705\n",
            "train accuracy 99.19 %\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.030\n",
            "[ep 32][  200/  391] loss: 0.041\n",
            "[ep 32][  300/  391] loss: 0.028\n",
            "test loss 0.7345379\n",
            "test accuracy 82.99 %\n",
            "train loss 0.036568996\n",
            "train accuracy 99.12 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.042\n",
            "[ep 33][  200/  391] loss: 0.040\n",
            "[ep 33][  300/  391] loss: 0.060\n",
            "test loss 0.69866455\n",
            "test accuracy 82.92 %\n",
            "train loss 0.022819122\n",
            "train accuracy 99.18 %\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.068\n",
            "[ep 34][  200/  391] loss: 0.051\n",
            "[ep 34][  300/  391] loss: 0.038\n",
            "test loss 0.73291314\n",
            "test accuracy 82.93 %\n",
            "train loss 0.057340614\n",
            "train accuracy 99.22 %\n",
            "Epoch 00034: reducing learning rate of group 0 to 1.5625e-03.\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.079\n",
            "[ep 35][  200/  391] loss: 0.035\n",
            "[ep 35][  300/  391] loss: 0.028\n",
            "test loss 0.72151434\n",
            "test accuracy 82.89 %\n",
            "train loss 0.07866539\n",
            "train accuracy 99.31 %\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.037\n",
            "[ep 36][  200/  391] loss: 0.042\n",
            "[ep 36][  300/  391] loss: 0.030\n",
            "test loss 0.7089891\n",
            "test accuracy 82.91 %\n",
            "train loss 0.03656119\n",
            "train accuracy 99.15 %\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.036\n",
            "[ep 37][  200/  391] loss: 0.064\n",
            "[ep 37][  300/  391] loss: 0.025\n",
            "test loss 0.6968207\n",
            "test accuracy 82.99 %\n",
            "train loss 0.032604016\n",
            "train accuracy 99.18 %\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.058\n",
            "[ep 38][  200/  391] loss: 0.035\n",
            "[ep 38][  300/  391] loss: 0.026\n",
            "test loss 0.70609415\n",
            "test accuracy 83.02 %\n",
            "train loss 0.043847676\n",
            "train accuracy 99.27 %\n",
            "Epoch 00038: reducing learning rate of group 0 to 7.8125e-04.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.058\n",
            "[ep 39][  200/  391] loss: 0.022\n",
            "[ep 39][  300/  391] loss: 0.041\n",
            "test loss 0.707951\n",
            "test accuracy 82.93 %\n",
            "train loss 0.019386403\n",
            "train accuracy 99.21 %\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.046\n",
            "[ep 40][  200/  391] loss: 0.070\n",
            "[ep 40][  300/  391] loss: 0.029\n",
            "test loss 0.71713984\n",
            "test accuracy 82.93 %\n",
            "train loss 0.095050305\n",
            "train accuracy 99.27 %\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.037\n",
            "[ep 41][  200/  391] loss: 0.063\n",
            "[ep 41][  300/  391] loss: 0.040\n",
            "test loss 0.72986966\n",
            "test accuracy 82.98 %\n",
            "train loss 0.024695465\n",
            "train accuracy 99.30 %\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.052\n",
            "[ep 42][  200/  391] loss: 0.038\n",
            "[ep 42][  300/  391] loss: 0.031\n",
            "test loss 0.72330314\n",
            "test accuracy 82.91 %\n",
            "train loss 0.030109938\n",
            "train accuracy 99.28 %\n",
            "Epoch 00042: reducing learning rate of group 0 to 3.9063e-04.\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.030\n",
            "[ep 43][  200/  391] loss: 0.036\n",
            "[ep 43][  300/  391] loss: 0.032\n",
            "test loss 0.72396886\n",
            "test accuracy 82.96 %\n",
            "train loss 0.103852056\n",
            "train accuracy 99.24 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.021\n",
            "[ep 44][  200/  391] loss: 0.045\n",
            "[ep 44][  300/  391] loss: 0.034\n",
            "test loss 0.720948\n",
            "test accuracy 82.95 %\n",
            "train loss 0.070191994\n",
            "train accuracy 99.28 %\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.025\n",
            "[ep 45][  200/  391] loss: 0.047\n",
            "[ep 45][  300/  391] loss: 0.049\n",
            "test loss 0.7223814\n",
            "test accuracy 82.99 %\n",
            "train loss 0.049162827\n",
            "train accuracy 99.28 %\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.039\n",
            "[ep 46][  200/  391] loss: 0.060\n",
            "[ep 46][  300/  391] loss: 0.069\n",
            "test loss 0.7264854\n",
            "test accuracy 82.98 %\n",
            "train loss 0.058868848\n",
            "train accuracy 99.24 %\n",
            "Epoch 00046: reducing learning rate of group 0 to 1.9531e-04.\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.057\n",
            "[ep 47][  200/  391] loss: 0.046\n",
            "[ep 47][  300/  391] loss: 0.037\n",
            "test loss 0.72627974\n",
            "test accuracy 82.99 %\n",
            "train loss 0.048464395\n",
            "train accuracy 99.23 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.075\n",
            "[ep 48][  200/  391] loss: 0.027\n",
            "[ep 48][  300/  391] loss: 0.042\n",
            "test loss 0.7274733\n",
            "test accuracy 82.99 %\n",
            "train loss 0.058592904\n",
            "train accuracy 99.28 %\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.020\n",
            "[ep 49][  200/  391] loss: 0.033\n",
            "[ep 49][  300/  391] loss: 0.074\n",
            "test loss 0.725557\n",
            "test accuracy 83.03 %\n",
            "train loss 0.047418993\n",
            "train accuracy 99.23 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.070\n",
            "[ep 50][  200/  391] loss: 0.061\n",
            "[ep 50][  300/  391] loss: 0.042\n",
            "test loss 0.7242664\n",
            "test accuracy 83.02 %\n",
            "train loss 0.081512555\n",
            "train accuracy 99.34 %\n",
            "Epoch 00050: reducing learning rate of group 0 to 9.7656e-05.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Eclab\\anaconda3\\envs\\pytorch37\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(2048, num_classes)\n",
        "#print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet50_SAM_model.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet50_SAM = model_module_SAM(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet50_SAM\", stats_resnet50_SAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ep 1][  100/  391] loss: 2.287\n",
            "[ep 1][  200/  391] loss: 1.503\n",
            "[ep 1][  300/  391] loss: 1.430\n",
            "test loss 1.3000727\n",
            "test accuracy 65.64 %\n",
            "train loss 1.2258074\n",
            "train accuracy 63.59 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 2][  100/  391] loss: 1.191\n",
            "[ep 2][  200/  391] loss: 1.017\n",
            "[ep 2][  300/  391] loss: 0.987\n",
            "test loss 0.9708352\n",
            "test accuracy 73.81 %\n",
            "train loss 0.98314476\n",
            "train accuracy 76.08 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 3][  100/  391] loss: 1.016\n",
            "[ep 3][  200/  391] loss: 0.683\n",
            "[ep 3][  300/  391] loss: 0.776\n",
            "test loss 0.85316694\n",
            "test accuracy 75.24 %\n",
            "train loss 0.5151474\n",
            "train accuracy 79.60 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 4][  100/  391] loss: 0.534\n",
            "[ep 4][  200/  391] loss: 0.654\n",
            "[ep 4][  300/  391] loss: 0.495\n",
            "test loss 0.8264072\n",
            "test accuracy 77.10 %\n",
            "train loss 0.55772245\n",
            "train accuracy 83.31 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 5][  100/  391] loss: 0.543\n",
            "[ep 5][  200/  391] loss: 0.563\n",
            "[ep 5][  300/  391] loss: 0.431\n",
            "test loss 0.7816184\n",
            "test accuracy 78.09 %\n",
            "train loss 0.45876282\n",
            "train accuracy 86.27 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 6][  100/  391] loss: 0.526\n",
            "[ep 6][  200/  391] loss: 0.397\n",
            "[ep 6][  300/  391] loss: 0.402\n",
            "test loss 0.7861359\n",
            "test accuracy 78.91 %\n",
            "train loss 0.36666697\n",
            "train accuracy 88.90 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 7][  100/  391] loss: 0.333\n",
            "[ep 7][  200/  391] loss: 0.355\n",
            "[ep 7][  300/  391] loss: 0.422\n",
            "test loss 0.9822992\n",
            "test accuracy 79.82 %\n",
            "train loss 0.43688804\n",
            "train accuracy 90.30 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 8][  100/  391] loss: 0.287\n",
            "[ep 8][  200/  391] loss: 0.394\n",
            "[ep 8][  300/  391] loss: 0.380\n",
            "test loss 0.74396896\n",
            "test accuracy 79.85 %\n",
            "train loss 0.35145992\n",
            "train accuracy 91.20 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 9][  100/  391] loss: 0.403\n",
            "[ep 9][  200/  391] loss: 0.266\n",
            "[ep 9][  300/  391] loss: 0.353\n",
            "test loss 0.9096845\n",
            "test accuracy 80.35 %\n",
            "train loss 0.22949353\n",
            "train accuracy 93.28 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 10][  100/  391] loss: 0.358\n",
            "[ep 10][  200/  391] loss: 0.230\n",
            "[ep 10][  300/  391] loss: 0.228\n",
            "test loss 1.3105129\n",
            "test accuracy 79.44 %\n",
            "train loss 0.2828334\n",
            "train accuracy 93.10 %\n",
            "--------------------------------------------------\n",
            "[ep 11][  100/  391] loss: 0.233\n",
            "[ep 11][  200/  391] loss: 0.123\n",
            "[ep 11][  300/  391] loss: 0.236\n",
            "test loss 1.0549374\n",
            "test accuracy 80.70 %\n",
            "train loss 0.20574102\n",
            "train accuracy 94.50 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 12][  100/  391] loss: 0.155\n",
            "[ep 12][  200/  391] loss: 0.121\n",
            "[ep 12][  300/  391] loss: 0.222\n",
            "test loss 0.7010274\n",
            "test accuracy 80.54 %\n",
            "train loss 0.09710728\n",
            "train accuracy 94.75 %\n",
            "--------------------------------------------------\n",
            "[ep 13][  100/  391] loss: 0.169\n",
            "[ep 13][  200/  391] loss: 0.174\n",
            "[ep 13][  300/  391] loss: 0.170\n",
            "test loss 0.6670127\n",
            "test accuracy 81.20 %\n",
            "train loss 0.17795163\n",
            "train accuracy 95.64 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 14][  100/  391] loss: 0.149\n",
            "[ep 14][  200/  391] loss: 0.103\n",
            "[ep 14][  300/  391] loss: 0.197\n",
            "test loss 0.8981581\n",
            "test accuracy 81.25 %\n",
            "train loss 0.14764932\n",
            "train accuracy 96.16 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 15][  100/  391] loss: 0.119\n",
            "[ep 15][  200/  391] loss: 0.117\n",
            "[ep 15][  300/  391] loss: 0.332\n",
            "test loss 0.92210466\n",
            "test accuracy 81.14 %\n",
            "train loss 0.16952948\n",
            "train accuracy 96.50 %\n",
            "--------------------------------------------------\n",
            "[ep 16][  100/  391] loss: 0.075\n",
            "[ep 16][  200/  391] loss: 0.133\n",
            "[ep 16][  300/  391] loss: 0.099\n",
            "test loss 0.84181345\n",
            "test accuracy 81.47 %\n",
            "train loss 0.16343333\n",
            "train accuracy 96.65 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 17][  100/  391] loss: 0.158\n",
            "[ep 17][  200/  391] loss: 0.097\n",
            "[ep 17][  300/  391] loss: 0.140\n",
            "test loss 1.0931405\n",
            "test accuracy 81.27 %\n",
            "train loss 0.07872999\n",
            "train accuracy 97.28 %\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-02.\n",
            "--------------------------------------------------\n",
            "[ep 18][  100/  391] loss: 0.077\n",
            "[ep 18][  200/  391] loss: 0.043\n",
            "[ep 18][  300/  391] loss: 0.078\n",
            "test loss 0.99326634\n",
            "test accuracy 82.55 %\n",
            "train loss 0.046978172\n",
            "train accuracy 98.43 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 19][  100/  391] loss: 0.060\n",
            "[ep 19][  200/  391] loss: 0.095\n",
            "[ep 19][  300/  391] loss: 0.104\n",
            "test loss 1.0886103\n",
            "test accuracy 82.98 %\n",
            "train loss 0.04607597\n",
            "train accuracy 98.70 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 20][  100/  391] loss: 0.033\n",
            "[ep 20][  200/  391] loss: 0.059\n",
            "[ep 20][  300/  391] loss: 0.083\n",
            "test loss 0.8490814\n",
            "test accuracy 83.03 %\n",
            "train loss 0.032010086\n",
            "train accuracy 98.92 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 21][  100/  391] loss: 0.046\n",
            "[ep 21][  200/  391] loss: 0.039\n",
            "[ep 21][  300/  391] loss: 0.064\n",
            "test loss 0.955724\n",
            "test accuracy 83.21 %\n",
            "train loss 0.08584493\n",
            "train accuracy 98.95 %\n",
            "Epoch 00021: reducing learning rate of group 0 to 2.5000e-02.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 22][  100/  391] loss: 0.046\n",
            "[ep 22][  200/  391] loss: 0.054\n",
            "[ep 22][  300/  391] loss: 0.029\n",
            "test loss 0.85668045\n",
            "test accuracy 83.58 %\n",
            "train loss 0.05322649\n",
            "train accuracy 99.19 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 23][  100/  391] loss: 0.077\n",
            "[ep 23][  200/  391] loss: 0.033\n",
            "[ep 23][  300/  391] loss: 0.038\n",
            "test loss 0.81801414\n",
            "test accuracy 83.32 %\n",
            "train loss 0.03179554\n",
            "train accuracy 99.20 %\n",
            "--------------------------------------------------\n",
            "[ep 24][  100/  391] loss: 0.062\n",
            "[ep 24][  200/  391] loss: 0.026\n",
            "[ep 24][  300/  391] loss: 0.065\n",
            "test loss 0.8429833\n",
            "test accuracy 83.56 %\n",
            "train loss 0.02849095\n",
            "train accuracy 99.29 %\n",
            "--------------------------------------------------\n",
            "[ep 25][  100/  391] loss: 0.038\n",
            "[ep 25][  200/  391] loss: 0.022\n",
            "[ep 25][  300/  391] loss: 0.099\n",
            "test loss 0.8979745\n",
            "test accuracy 83.40 %\n",
            "train loss 0.060513206\n",
            "train accuracy 99.27 %\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.2500e-02.\n",
            "--------------------------------------------------\n",
            "[ep 26][  100/  391] loss: 0.069\n",
            "[ep 26][  200/  391] loss: 0.040\n",
            "[ep 26][  300/  391] loss: 0.062\n",
            "test loss 0.8877248\n",
            "test accuracy 83.72 %\n",
            "train loss 0.061609425\n",
            "train accuracy 99.41 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 27][  100/  391] loss: 0.043\n",
            "[ep 27][  200/  391] loss: 0.016\n",
            "[ep 27][  300/  391] loss: 0.023\n",
            "test loss 0.9638009\n",
            "test accuracy 83.81 %\n",
            "train loss 0.029320667\n",
            "train accuracy 99.45 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 28][  100/  391] loss: 0.020\n",
            "[ep 28][  200/  391] loss: 0.030\n",
            "[ep 28][  300/  391] loss: 0.039\n",
            "test loss 0.9638387\n",
            "test accuracy 83.67 %\n",
            "train loss 0.010896473\n",
            "train accuracy 99.37 %\n",
            "--------------------------------------------------\n",
            "[ep 29][  100/  391] loss: 0.016\n",
            "[ep 29][  200/  391] loss: 0.046\n",
            "[ep 29][  300/  391] loss: 0.031\n",
            "test loss 0.9404128\n",
            "test accuracy 83.80 %\n",
            "train loss 0.042782955\n",
            "train accuracy 99.44 %\n",
            "Epoch 00029: reducing learning rate of group 0 to 6.2500e-03.\n",
            "--------------------------------------------------\n",
            "[ep 30][  100/  391] loss: 0.037\n",
            "[ep 30][  200/  391] loss: 0.029\n",
            "[ep 30][  300/  391] loss: 0.053\n",
            "test loss 0.9587929\n",
            "test accuracy 83.83 %\n",
            "train loss 0.012127339\n",
            "train accuracy 99.47 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 31][  100/  391] loss: 0.018\n",
            "[ep 31][  200/  391] loss: 0.009\n",
            "[ep 31][  300/  391] loss: 0.011\n",
            "test loss 0.97748053\n",
            "test accuracy 83.86 %\n",
            "train loss 0.06839471\n",
            "train accuracy 99.45 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 32][  100/  391] loss: 0.037\n",
            "[ep 32][  200/  391] loss: 0.031\n",
            "[ep 32][  300/  391] loss: 0.028\n",
            "test loss 0.96808624\n",
            "test accuracy 83.68 %\n",
            "train loss 0.076201595\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 33][  100/  391] loss: 0.015\n",
            "[ep 33][  200/  391] loss: 0.031\n",
            "[ep 33][  300/  391] loss: 0.025\n",
            "test loss 0.96932924\n",
            "test accuracy 83.67 %\n",
            "train loss 0.039461896\n",
            "train accuracy 99.48 %\n",
            "Epoch 00033: reducing learning rate of group 0 to 3.1250e-03.\n",
            "--------------------------------------------------\n",
            "[ep 34][  100/  391] loss: 0.044\n",
            "[ep 34][  200/  391] loss: 0.044\n",
            "[ep 34][  300/  391] loss: 0.033\n",
            "test loss 0.95979476\n",
            "test accuracy 83.66 %\n",
            "train loss 0.02243467\n",
            "train accuracy 99.42 %\n",
            "--------------------------------------------------\n",
            "[ep 35][  100/  391] loss: 0.014\n",
            "[ep 35][  200/  391] loss: 0.049\n",
            "[ep 35][  300/  391] loss: 0.024\n",
            "test loss 0.950631\n",
            "test accuracy 83.79 %\n",
            "train loss 0.06491522\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 36][  100/  391] loss: 0.027\n",
            "[ep 36][  200/  391] loss: 0.035\n",
            "[ep 36][  300/  391] loss: 0.045\n",
            "test loss 0.9491128\n",
            "test accuracy 83.74 %\n",
            "train loss 0.010029203\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 37][  100/  391] loss: 0.023\n",
            "[ep 37][  200/  391] loss: 0.031\n",
            "[ep 37][  300/  391] loss: 0.014\n",
            "test loss 0.9336321\n",
            "test accuracy 83.85 %\n",
            "train loss 0.030074066\n",
            "train accuracy 99.53 %\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.5625e-03.\n",
            "--------------------------------------------------\n",
            "[ep 38][  100/  391] loss: 0.032\n",
            "[ep 38][  200/  391] loss: 0.054\n",
            "[ep 38][  300/  391] loss: 0.028\n",
            "test loss 0.9392835\n",
            "test accuracy 83.83 %\n",
            "train loss 0.008896625\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 39][  100/  391] loss: 0.022\n",
            "[ep 39][  200/  391] loss: 0.026\n",
            "[ep 39][  300/  391] loss: 0.016\n",
            "test loss 0.9297694\n",
            "test accuracy 83.83 %\n",
            "train loss 0.06560554\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 40][  100/  391] loss: 0.057\n",
            "[ep 40][  200/  391] loss: 0.037\n",
            "[ep 40][  300/  391] loss: 0.015\n",
            "test loss 0.92281204\n",
            "test accuracy 83.89 %\n",
            "train loss 0.011309996\n",
            "train accuracy 99.57 %\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 41][  100/  391] loss: 0.023\n",
            "[ep 41][  200/  391] loss: 0.039\n",
            "[ep 41][  300/  391] loss: 0.026\n",
            "test loss 0.9244926\n",
            "test accuracy 83.98 %\n",
            "train loss 0.034097366\n",
            "train accuracy 99.51 %\n",
            "Epoch 00041: reducing learning rate of group 0 to 7.8125e-04.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 42][  100/  391] loss: 0.045\n",
            "[ep 42][  200/  391] loss: 0.016\n",
            "[ep 42][  300/  391] loss: 0.023\n",
            "test loss 0.9287343\n",
            "test accuracy 83.94 %\n",
            "train loss 0.010327971\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 43][  100/  391] loss: 0.026\n",
            "[ep 43][  200/  391] loss: 0.024\n",
            "[ep 43][  300/  391] loss: 0.016\n",
            "test loss 0.93087083\n",
            "test accuracy 83.94 %\n",
            "train loss 0.022034427\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 44][  100/  391] loss: 0.012\n",
            "[ep 44][  200/  391] loss: 0.036\n",
            "[ep 44][  300/  391] loss: 0.051\n",
            "test loss 0.9309102\n",
            "test accuracy 83.95 %\n",
            "train loss 0.024527604\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 45][  100/  391] loss: 0.056\n",
            "[ep 45][  200/  391] loss: 0.011\n",
            "[ep 45][  300/  391] loss: 0.021\n",
            "test loss 0.93082786\n",
            "test accuracy 83.97 %\n",
            "train loss 0.020444136\n",
            "train accuracy 99.52 %\n",
            "Epoch 00045: reducing learning rate of group 0 to 3.9063e-04.\n",
            "--------------------------------------------------\n",
            "[ep 46][  100/  391] loss: 0.025\n",
            "[ep 46][  200/  391] loss: 0.021\n",
            "[ep 46][  300/  391] loss: 0.038\n",
            "test loss 0.93293816\n",
            "test accuracy 83.97 %\n",
            "train loss 0.030036608\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 47][  100/  391] loss: 0.031\n",
            "[ep 47][  200/  391] loss: 0.017\n",
            "[ep 47][  300/  391] loss: 0.034\n",
            "test loss 0.9365598\n",
            "test accuracy 83.94 %\n",
            "train loss 0.0060304934\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 48][  100/  391] loss: 0.022\n",
            "[ep 48][  200/  391] loss: 0.073\n",
            "[ep 48][  300/  391] loss: 0.010\n",
            "test loss 0.93752307\n",
            "test accuracy 83.96 %\n",
            "train loss 0.014689612\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 49][  100/  391] loss: 0.050\n",
            "[ep 49][  200/  391] loss: 0.034\n",
            "[ep 49][  300/  391] loss: 0.010\n",
            "test loss 0.9390141\n",
            "test accuracy 84.01 %\n",
            "train loss 0.04979853\n",
            "train accuracy 99.48 %\n",
            "Epoch 00049: reducing learning rate of group 0 to 1.9531e-04.\n",
            "model saved !\n",
            "--------------------------------------------------\n",
            "[ep 50][  100/  391] loss: 0.042\n",
            "[ep 50][  200/  391] loss: 0.047\n",
            "[ep 50][  300/  391] loss: 0.014\n",
            "test loss 0.93814117\n",
            "test accuracy 84.00 %\n",
            "train loss 0.028129209\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 51][  100/  391] loss: 0.017\n",
            "[ep 51][  200/  391] loss: 0.015\n",
            "[ep 51][  300/  391] loss: 0.027\n",
            "test loss 0.9389727\n",
            "test accuracy 84.00 %\n",
            "train loss 0.02544722\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 52][  100/  391] loss: 0.021\n",
            "[ep 52][  200/  391] loss: 0.038\n",
            "[ep 52][  300/  391] loss: 0.020\n",
            "test loss 0.93901944\n",
            "test accuracy 83.97 %\n",
            "train loss 0.04051764\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 53][  100/  391] loss: 0.026\n",
            "[ep 53][  200/  391] loss: 0.029\n",
            "[ep 53][  300/  391] loss: 0.019\n",
            "test loss 0.939648\n",
            "test accuracy 83.93 %\n",
            "train loss 0.019503059\n",
            "train accuracy 99.49 %\n",
            "Epoch 00053: reducing learning rate of group 0 to 9.7656e-05.\n",
            "--------------------------------------------------\n",
            "[ep 54][  100/  391] loss: 0.029\n",
            "[ep 54][  200/  391] loss: 0.026\n",
            "[ep 54][  300/  391] loss: 0.020\n",
            "test loss 0.9402483\n",
            "test accuracy 83.95 %\n",
            "train loss 0.010394746\n",
            "train accuracy 99.48 %\n",
            "--------------------------------------------------\n",
            "[ep 55][  100/  391] loss: 0.012\n",
            "[ep 55][  200/  391] loss: 0.018\n",
            "[ep 55][  300/  391] loss: 0.072\n",
            "test loss 0.9394606\n",
            "test accuracy 83.95 %\n",
            "train loss 0.069765694\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 56][  100/  391] loss: 0.016\n",
            "[ep 56][  200/  391] loss: 0.026\n",
            "[ep 56][  300/  391] loss: 0.022\n",
            "test loss 0.9395584\n",
            "test accuracy 83.95 %\n",
            "train loss 0.008702071\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 57][  100/  391] loss: 0.021\n",
            "[ep 57][  200/  391] loss: 0.023\n",
            "[ep 57][  300/  391] loss: 0.030\n",
            "test loss 0.93918\n",
            "test accuracy 83.94 %\n",
            "train loss 0.013828268\n",
            "train accuracy 99.51 %\n",
            "Epoch 00057: reducing learning rate of group 0 to 4.8828e-05.\n",
            "--------------------------------------------------\n",
            "[ep 58][  100/  391] loss: 0.021\n",
            "[ep 58][  200/  391] loss: 0.013\n",
            "[ep 58][  300/  391] loss: 0.009\n",
            "test loss 0.9398414\n",
            "test accuracy 83.94 %\n",
            "train loss 0.0279122\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 59][  100/  391] loss: 0.012\n",
            "[ep 59][  200/  391] loss: 0.019\n",
            "[ep 59][  300/  391] loss: 0.024\n",
            "test loss 0.9395521\n",
            "test accuracy 83.94 %\n",
            "train loss 0.056820996\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 60][  100/  391] loss: 0.017\n",
            "[ep 60][  200/  391] loss: 0.036\n",
            "[ep 60][  300/  391] loss: 0.028\n",
            "test loss 0.9396643\n",
            "test accuracy 83.95 %\n",
            "train loss 0.05444622\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 61][  100/  391] loss: 0.030\n",
            "[ep 61][  200/  391] loss: 0.022\n",
            "[ep 61][  300/  391] loss: 0.023\n",
            "test loss 0.9402117\n",
            "test accuracy 83.96 %\n",
            "train loss 0.020372745\n",
            "train accuracy 99.56 %\n",
            "Epoch 00061: reducing learning rate of group 0 to 2.4414e-05.\n",
            "--------------------------------------------------\n",
            "[ep 62][  100/  391] loss: 0.016\n",
            "[ep 62][  200/  391] loss: 0.020\n",
            "[ep 62][  300/  391] loss: 0.016\n",
            "test loss 0.9400026\n",
            "test accuracy 83.96 %\n",
            "train loss 0.062137287\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 63][  100/  391] loss: 0.014\n",
            "[ep 63][  200/  391] loss: 0.011\n",
            "[ep 63][  300/  391] loss: 0.021\n",
            "test loss 0.9397979\n",
            "test accuracy 83.96 %\n",
            "train loss 0.035729095\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 64][  100/  391] loss: 0.047\n",
            "[ep 64][  200/  391] loss: 0.017\n",
            "[ep 64][  300/  391] loss: 0.026\n",
            "test loss 0.93988127\n",
            "test accuracy 83.96 %\n",
            "train loss 0.026945654\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 65][  100/  391] loss: 0.022\n",
            "[ep 65][  200/  391] loss: 0.018\n",
            "[ep 65][  300/  391] loss: 0.011\n",
            "test loss 0.9398782\n",
            "test accuracy 83.97 %\n",
            "train loss 0.022634115\n",
            "train accuracy 99.56 %\n",
            "Epoch 00065: reducing learning rate of group 0 to 1.2207e-05.\n",
            "--------------------------------------------------\n",
            "[ep 66][  100/  391] loss: 0.014\n",
            "[ep 66][  200/  391] loss: 0.044\n",
            "[ep 66][  300/  391] loss: 0.064\n",
            "test loss 0.9394942\n",
            "test accuracy 83.96 %\n",
            "train loss 0.03659107\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 67][  100/  391] loss: 0.017\n",
            "[ep 67][  200/  391] loss: 0.034\n",
            "[ep 67][  300/  391] loss: 0.011\n",
            "test loss 0.93976325\n",
            "test accuracy 83.96 %\n",
            "train loss 0.021698713\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 68][  100/  391] loss: 0.024\n",
            "[ep 68][  200/  391] loss: 0.020\n",
            "[ep 68][  300/  391] loss: 0.014\n",
            "test loss 0.93952996\n",
            "test accuracy 83.98 %\n",
            "train loss 0.044681024\n",
            "train accuracy 99.47 %\n",
            "--------------------------------------------------\n",
            "[ep 69][  100/  391] loss: 0.050\n",
            "[ep 69][  200/  391] loss: 0.029\n",
            "[ep 69][  300/  391] loss: 0.015\n",
            "test loss 0.93936104\n",
            "test accuracy 83.98 %\n",
            "train loss 0.009403391\n",
            "train accuracy 99.52 %\n",
            "Epoch 00069: reducing learning rate of group 0 to 6.1035e-06.\n",
            "--------------------------------------------------\n",
            "[ep 70][  100/  391] loss: 0.045\n",
            "[ep 70][  200/  391] loss: 0.045\n",
            "[ep 70][  300/  391] loss: 0.044\n",
            "test loss 0.93959504\n",
            "test accuracy 83.98 %\n",
            "train loss 0.034900628\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 71][  100/  391] loss: 0.026\n",
            "[ep 71][  200/  391] loss: 0.077\n",
            "[ep 71][  300/  391] loss: 0.036\n",
            "test loss 0.9395281\n",
            "test accuracy 83.98 %\n",
            "train loss 0.022549096\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 72][  100/  391] loss: 0.051\n",
            "[ep 72][  200/  391] loss: 0.022\n",
            "[ep 72][  300/  391] loss: 0.044\n",
            "test loss 0.9394847\n",
            "test accuracy 83.97 %\n",
            "train loss 0.020678733\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 73][  100/  391] loss: 0.011\n",
            "[ep 73][  200/  391] loss: 0.030\n",
            "[ep 73][  300/  391] loss: 0.035\n",
            "test loss 0.93945783\n",
            "test accuracy 83.98 %\n",
            "train loss 0.010742964\n",
            "train accuracy 99.57 %\n",
            "Epoch 00073: reducing learning rate of group 0 to 3.0518e-06.\n",
            "--------------------------------------------------\n",
            "[ep 74][  100/  391] loss: 0.028\n",
            "[ep 74][  200/  391] loss: 0.034\n",
            "[ep 74][  300/  391] loss: 0.039\n",
            "test loss 0.939618\n",
            "test accuracy 83.98 %\n",
            "train loss 0.030333508\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 75][  100/  391] loss: 0.030\n",
            "[ep 75][  200/  391] loss: 0.014\n",
            "[ep 75][  300/  391] loss: 0.025\n",
            "test loss 0.939564\n",
            "test accuracy 83.98 %\n",
            "train loss 0.016773775\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 76][  100/  391] loss: 0.018\n",
            "[ep 76][  200/  391] loss: 0.017\n",
            "[ep 76][  300/  391] loss: 0.082\n",
            "test loss 0.9396981\n",
            "test accuracy 83.98 %\n",
            "train loss 0.020623496\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 77][  100/  391] loss: 0.048\n",
            "[ep 77][  200/  391] loss: 0.020\n",
            "[ep 77][  300/  391] loss: 0.023\n",
            "test loss 0.9394856\n",
            "test accuracy 83.98 %\n",
            "train loss 0.045142617\n",
            "train accuracy 99.53 %\n",
            "Epoch 00077: reducing learning rate of group 0 to 1.5259e-06.\n",
            "--------------------------------------------------\n",
            "[ep 78][  100/  391] loss: 0.056\n",
            "[ep 78][  200/  391] loss: 0.020\n",
            "[ep 78][  300/  391] loss: 0.021\n",
            "test loss 0.93948185\n",
            "test accuracy 83.96 %\n",
            "train loss 0.03655364\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 79][  100/  391] loss: 0.036\n",
            "[ep 79][  200/  391] loss: 0.037\n",
            "[ep 79][  300/  391] loss: 0.027\n",
            "test loss 0.93959045\n",
            "test accuracy 83.98 %\n",
            "train loss 0.010106953\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 80][  100/  391] loss: 0.040\n",
            "[ep 80][  200/  391] loss: 0.036\n",
            "[ep 80][  300/  391] loss: 0.009\n",
            "test loss 0.93941194\n",
            "test accuracy 83.97 %\n",
            "train loss 0.009153852\n",
            "train accuracy 99.58 %\n",
            "--------------------------------------------------\n",
            "[ep 81][  100/  391] loss: 0.048\n",
            "[ep 81][  200/  391] loss: 0.023\n",
            "[ep 81][  300/  391] loss: 0.039\n",
            "test loss 0.93957293\n",
            "test accuracy 83.98 %\n",
            "train loss 0.009471463\n",
            "train accuracy 99.55 %\n",
            "Epoch 00081: reducing learning rate of group 0 to 7.6294e-07.\n",
            "--------------------------------------------------\n",
            "[ep 82][  100/  391] loss: 0.050\n",
            "[ep 82][  200/  391] loss: 0.037\n",
            "[ep 82][  300/  391] loss: 0.011\n",
            "test loss 0.93946636\n",
            "test accuracy 83.97 %\n",
            "train loss 0.034192737\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 83][  100/  391] loss: 0.024\n",
            "[ep 83][  200/  391] loss: 0.016\n",
            "[ep 83][  300/  391] loss: 0.015\n",
            "test loss 0.93942237\n",
            "test accuracy 83.98 %\n",
            "train loss 0.047216356\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 84][  100/  391] loss: 0.029\n",
            "[ep 84][  200/  391] loss: 0.021\n",
            "[ep 84][  300/  391] loss: 0.061\n",
            "test loss 0.9396706\n",
            "test accuracy 83.97 %\n",
            "train loss 0.02928931\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 85][  100/  391] loss: 0.035\n",
            "[ep 85][  200/  391] loss: 0.042\n",
            "[ep 85][  300/  391] loss: 0.019\n",
            "test loss 0.9396824\n",
            "test accuracy 83.98 %\n",
            "train loss 0.0283085\n",
            "train accuracy 99.54 %\n",
            "Epoch 00085: reducing learning rate of group 0 to 3.8147e-07.\n",
            "--------------------------------------------------\n",
            "[ep 86][  100/  391] loss: 0.035\n",
            "[ep 86][  200/  391] loss: 0.020\n",
            "[ep 86][  300/  391] loss: 0.012\n",
            "test loss 0.939477\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01285921\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 87][  100/  391] loss: 0.030\n",
            "[ep 87][  200/  391] loss: 0.026\n",
            "[ep 87][  300/  391] loss: 0.052\n",
            "test loss 0.9395925\n",
            "test accuracy 83.98 %\n",
            "train loss 0.046242394\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 88][  100/  391] loss: 0.016\n",
            "[ep 88][  200/  391] loss: 0.014\n",
            "[ep 88][  300/  391] loss: 0.043\n",
            "test loss 0.939679\n",
            "test accuracy 83.98 %\n",
            "train loss 0.046297576\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 89][  100/  391] loss: 0.010\n",
            "[ep 89][  200/  391] loss: 0.014\n",
            "[ep 89][  300/  391] loss: 0.016\n",
            "test loss 0.93952155\n",
            "test accuracy 83.97 %\n",
            "train loss 0.022756767\n",
            "train accuracy 99.55 %\n",
            "Epoch 00089: reducing learning rate of group 0 to 1.9073e-07.\n",
            "--------------------------------------------------\n",
            "[ep 90][  100/  391] loss: 0.025\n",
            "[ep 90][  200/  391] loss: 0.052\n",
            "[ep 90][  300/  391] loss: 0.016\n",
            "test loss 0.93960285\n",
            "test accuracy 83.98 %\n",
            "train loss 0.060574345\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 91][  100/  391] loss: 0.017\n",
            "[ep 91][  200/  391] loss: 0.040\n",
            "[ep 91][  300/  391] loss: 0.057\n",
            "test loss 0.9395827\n",
            "test accuracy 83.97 %\n",
            "train loss 0.019440614\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 92][  100/  391] loss: 0.027\n",
            "[ep 92][  200/  391] loss: 0.016\n",
            "[ep 92][  300/  391] loss: 0.018\n",
            "test loss 0.9395864\n",
            "test accuracy 83.97 %\n",
            "train loss 0.019937994\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 93][  100/  391] loss: 0.026\n",
            "[ep 93][  200/  391] loss: 0.028\n",
            "[ep 93][  300/  391] loss: 0.020\n",
            "test loss 0.9394075\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014105542\n",
            "train accuracy 99.51 %\n",
            "Epoch 00093: reducing learning rate of group 0 to 9.5367e-08.\n",
            "--------------------------------------------------\n",
            "[ep 94][  100/  391] loss: 0.014\n",
            "[ep 94][  200/  391] loss: 0.058\n",
            "[ep 94][  300/  391] loss: 0.020\n",
            "test loss 0.93961704\n",
            "test accuracy 83.98 %\n",
            "train loss 0.048739247\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 95][  100/  391] loss: 0.038\n",
            "[ep 95][  200/  391] loss: 0.028\n",
            "[ep 95][  300/  391] loss: 0.017\n",
            "test loss 0.9395256\n",
            "test accuracy 83.98 %\n",
            "train loss 0.016553028\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 96][  100/  391] loss: 0.024\n",
            "[ep 96][  200/  391] loss: 0.024\n",
            "[ep 96][  300/  391] loss: 0.047\n",
            "test loss 0.9395642\n",
            "test accuracy 83.98 %\n",
            "train loss 0.012020743\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 97][  100/  391] loss: 0.019\n",
            "[ep 97][  200/  391] loss: 0.030\n",
            "[ep 97][  300/  391] loss: 0.057\n",
            "test loss 0.9394903\n",
            "test accuracy 83.98 %\n",
            "train loss 0.015755929\n",
            "train accuracy 99.53 %\n",
            "Epoch 00097: reducing learning rate of group 0 to 4.7684e-08.\n",
            "--------------------------------------------------\n",
            "[ep 98][  100/  391] loss: 0.024\n",
            "[ep 98][  200/  391] loss: 0.032\n",
            "[ep 98][  300/  391] loss: 0.035\n",
            "test loss 0.9396706\n",
            "test accuracy 83.98 %\n",
            "train loss 0.017561601\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 99][  100/  391] loss: 0.019\n",
            "[ep 99][  200/  391] loss: 0.027\n",
            "[ep 99][  300/  391] loss: 0.031\n",
            "test loss 0.93956226\n",
            "test accuracy 83.98 %\n",
            "train loss 0.025076434\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 100][  100/  391] loss: 0.022\n",
            "[ep 100][  200/  391] loss: 0.011\n",
            "[ep 100][  300/  391] loss: 0.034\n",
            "test loss 0.9395647\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03870579\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 101][  100/  391] loss: 0.024\n",
            "[ep 101][  200/  391] loss: 0.008\n",
            "[ep 101][  300/  391] loss: 0.016\n",
            "test loss 0.93952656\n",
            "test accuracy 83.98 %\n",
            "train loss 0.026098913\n",
            "train accuracy 99.53 %\n",
            "Epoch 00101: reducing learning rate of group 0 to 2.3842e-08.\n",
            "--------------------------------------------------\n",
            "[ep 102][  100/  391] loss: 0.037\n",
            "[ep 102][  200/  391] loss: 0.015\n",
            "[ep 102][  300/  391] loss: 0.042\n",
            "test loss 0.9395426\n",
            "test accuracy 83.98 %\n",
            "train loss 0.037562728\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 103][  100/  391] loss: 0.015\n",
            "[ep 103][  200/  391] loss: 0.023\n",
            "[ep 103][  300/  391] loss: 0.025\n",
            "test loss 0.93946403\n",
            "test accuracy 83.98 %\n",
            "train loss 0.030176375\n",
            "train accuracy 99.61 %\n",
            "--------------------------------------------------\n",
            "[ep 104][  100/  391] loss: 0.032\n",
            "[ep 104][  200/  391] loss: 0.030\n",
            "[ep 104][  300/  391] loss: 0.034\n",
            "test loss 0.9395205\n",
            "test accuracy 83.98 %\n",
            "train loss 0.016608788\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 105][  100/  391] loss: 0.021\n",
            "[ep 105][  200/  391] loss: 0.023\n",
            "[ep 105][  300/  391] loss: 0.033\n",
            "test loss 0.9394679\n",
            "test accuracy 83.98 %\n",
            "train loss 0.015140405\n",
            "train accuracy 99.58 %\n",
            "Epoch 00105: reducing learning rate of group 0 to 1.1921e-08.\n",
            "--------------------------------------------------\n",
            "[ep 106][  100/  391] loss: 0.016\n",
            "[ep 106][  200/  391] loss: 0.018\n",
            "[ep 106][  300/  391] loss: 0.026\n",
            "test loss 0.93945724\n",
            "test accuracy 83.97 %\n",
            "train loss 0.012517391\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 107][  100/  391] loss: 0.054\n",
            "[ep 107][  200/  391] loss: 0.022\n",
            "[ep 107][  300/  391] loss: 0.029\n",
            "test loss 0.9395712\n",
            "test accuracy 83.98 %\n",
            "train loss 0.021121088\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 108][  100/  391] loss: 0.029\n",
            "[ep 108][  200/  391] loss: 0.011\n",
            "[ep 108][  300/  391] loss: 0.026\n",
            "test loss 0.93951607\n",
            "test accuracy 83.98 %\n",
            "train loss 0.019154862\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 109][  100/  391] loss: 0.012\n",
            "[ep 109][  200/  391] loss: 0.026\n",
            "[ep 109][  300/  391] loss: 0.013\n",
            "test loss 0.9394279\n",
            "test accuracy 83.98 %\n",
            "train loss 0.06008798\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 110][  100/  391] loss: 0.014\n",
            "[ep 110][  200/  391] loss: 0.029\n",
            "[ep 110][  300/  391] loss: 0.027\n",
            "test loss 0.9395701\n",
            "test accuracy 83.97 %\n",
            "train loss 0.050902523\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 111][  100/  391] loss: 0.015\n",
            "[ep 111][  200/  391] loss: 0.041\n",
            "[ep 111][  300/  391] loss: 0.015\n",
            "test loss 0.93961036\n",
            "test accuracy 83.98 %\n",
            "train loss 0.0063531166\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 112][  100/  391] loss: 0.014\n",
            "[ep 112][  200/  391] loss: 0.021\n",
            "[ep 112][  300/  391] loss: 0.028\n",
            "test loss 0.93957406\n",
            "test accuracy 83.98 %\n",
            "train loss 0.021121796\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 113][  100/  391] loss: 0.010\n",
            "[ep 113][  200/  391] loss: 0.030\n",
            "[ep 113][  300/  391] loss: 0.032\n",
            "test loss 0.9396548\n",
            "test accuracy 83.97 %\n",
            "train loss 0.036725376\n",
            "train accuracy 99.58 %\n",
            "--------------------------------------------------\n",
            "[ep 114][  100/  391] loss: 0.039\n",
            "[ep 114][  200/  391] loss: 0.036\n",
            "[ep 114][  300/  391] loss: 0.025\n",
            "test loss 0.9395573\n",
            "test accuracy 83.97 %\n",
            "train loss 0.038176868\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 115][  100/  391] loss: 0.016\n",
            "[ep 115][  200/  391] loss: 0.016\n",
            "[ep 115][  300/  391] loss: 0.012\n",
            "test loss 0.9395316\n",
            "test accuracy 83.98 %\n",
            "train loss 0.041737873\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 116][  100/  391] loss: 0.022\n",
            "[ep 116][  200/  391] loss: 0.031\n",
            "[ep 116][  300/  391] loss: 0.021\n",
            "test loss 0.9396918\n",
            "test accuracy 83.98 %\n",
            "train loss 0.0379485\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 117][  100/  391] loss: 0.025\n",
            "[ep 117][  200/  391] loss: 0.030\n",
            "[ep 117][  300/  391] loss: 0.018\n",
            "test loss 0.9395183\n",
            "test accuracy 83.98 %\n",
            "train loss 0.039905045\n",
            "train accuracy 99.48 %\n",
            "--------------------------------------------------\n",
            "[ep 118][  100/  391] loss: 0.031\n",
            "[ep 118][  200/  391] loss: 0.011\n",
            "[ep 118][  300/  391] loss: 0.018\n",
            "test loss 0.93945533\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03919954\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 119][  100/  391] loss: 0.011\n",
            "[ep 119][  200/  391] loss: 0.021\n",
            "[ep 119][  300/  391] loss: 0.017\n",
            "test loss 0.9396363\n",
            "test accuracy 83.98 %\n",
            "train loss 0.009930271\n",
            "train accuracy 99.60 %\n",
            "--------------------------------------------------\n",
            "[ep 120][  100/  391] loss: 0.069\n",
            "[ep 120][  200/  391] loss: 0.033\n",
            "[ep 120][  300/  391] loss: 0.036\n",
            "test loss 0.9395784\n",
            "test accuracy 83.98 %\n",
            "train loss 0.034389183\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 121][  100/  391] loss: 0.023\n",
            "[ep 121][  200/  391] loss: 0.010\n",
            "[ep 121][  300/  391] loss: 0.018\n",
            "test loss 0.93951946\n",
            "test accuracy 83.97 %\n",
            "train loss 0.015939293\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 122][  100/  391] loss: 0.052\n",
            "[ep 122][  200/  391] loss: 0.024\n",
            "[ep 122][  300/  391] loss: 0.030\n",
            "test loss 0.9394676\n",
            "test accuracy 83.98 %\n",
            "train loss 0.06428017\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 123][  100/  391] loss: 0.020\n",
            "[ep 123][  200/  391] loss: 0.037\n",
            "[ep 123][  300/  391] loss: 0.028\n",
            "test loss 0.9396144\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01719194\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 124][  100/  391] loss: 0.023\n",
            "[ep 124][  200/  391] loss: 0.042\n",
            "[ep 124][  300/  391] loss: 0.031\n",
            "test loss 0.9395005\n",
            "test accuracy 83.98 %\n",
            "train loss 0.070062\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 125][  100/  391] loss: 0.091\n",
            "[ep 125][  200/  391] loss: 0.018\n",
            "[ep 125][  300/  391] loss: 0.024\n",
            "test loss 0.9395352\n",
            "test accuracy 83.98 %\n",
            "train loss 0.07998724\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 126][  100/  391] loss: 0.033\n",
            "[ep 126][  200/  391] loss: 0.051\n",
            "[ep 126][  300/  391] loss: 0.032\n",
            "test loss 0.9396609\n",
            "test accuracy 83.98 %\n",
            "train loss 0.04034776\n",
            "train accuracy 99.46 %\n",
            "--------------------------------------------------\n",
            "[ep 127][  100/  391] loss: 0.029\n",
            "[ep 127][  200/  391] loss: 0.043\n",
            "[ep 127][  300/  391] loss: 0.015\n",
            "test loss 0.9395423\n",
            "test accuracy 83.98 %\n",
            "train loss 0.04121641\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 128][  100/  391] loss: 0.013\n",
            "[ep 128][  200/  391] loss: 0.020\n",
            "[ep 128][  300/  391] loss: 0.059\n",
            "test loss 0.9396079\n",
            "test accuracy 83.98 %\n",
            "train loss 0.060559493\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 129][  100/  391] loss: 0.056\n",
            "[ep 129][  200/  391] loss: 0.031\n",
            "[ep 129][  300/  391] loss: 0.017\n",
            "test loss 0.93965644\n",
            "test accuracy 83.98 %\n",
            "train loss 0.026708161\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 130][  100/  391] loss: 0.015\n",
            "[ep 130][  200/  391] loss: 0.024\n",
            "[ep 130][  300/  391] loss: 0.026\n",
            "test loss 0.9395477\n",
            "test accuracy 83.98 %\n",
            "train loss 0.021258887\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 131][  100/  391] loss: 0.019\n",
            "[ep 131][  200/  391] loss: 0.015\n",
            "[ep 131][  300/  391] loss: 0.031\n",
            "test loss 0.9397853\n",
            "test accuracy 83.98 %\n",
            "train loss 0.029822756\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 132][  100/  391] loss: 0.017\n",
            "[ep 132][  200/  391] loss: 0.028\n",
            "[ep 132][  300/  391] loss: 0.025\n",
            "test loss 0.93960005\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014143278\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 133][  100/  391] loss: 0.014\n",
            "[ep 133][  200/  391] loss: 0.022\n",
            "[ep 133][  300/  391] loss: 0.012\n",
            "test loss 0.9394969\n",
            "test accuracy 83.98 %\n",
            "train loss 0.008666643\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 134][  100/  391] loss: 0.016\n",
            "[ep 134][  200/  391] loss: 0.009\n",
            "[ep 134][  300/  391] loss: 0.026\n",
            "test loss 0.93939954\n",
            "test accuracy 83.98 %\n",
            "train loss 0.0239795\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 135][  100/  391] loss: 0.022\n",
            "[ep 135][  200/  391] loss: 0.019\n",
            "[ep 135][  300/  391] loss: 0.044\n",
            "test loss 0.9393634\n",
            "test accuracy 83.98 %\n",
            "train loss 0.035200678\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 136][  100/  391] loss: 0.024\n",
            "[ep 136][  200/  391] loss: 0.018\n",
            "[ep 136][  300/  391] loss: 0.033\n",
            "test loss 0.9395847\n",
            "test accuracy 83.98 %\n",
            "train loss 0.06361182\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 137][  100/  391] loss: 0.017\n",
            "[ep 137][  200/  391] loss: 0.021\n",
            "[ep 137][  300/  391] loss: 0.060\n",
            "test loss 0.93955326\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03682281\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 138][  100/  391] loss: 0.017\n",
            "[ep 138][  200/  391] loss: 0.056\n",
            "[ep 138][  300/  391] loss: 0.022\n",
            "test loss 0.9395546\n",
            "test accuracy 83.98 %\n",
            "train loss 0.019657293\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 139][  100/  391] loss: 0.011\n",
            "[ep 139][  200/  391] loss: 0.010\n",
            "[ep 139][  300/  391] loss: 0.026\n",
            "test loss 0.93941665\n",
            "test accuracy 83.98 %\n",
            "train loss 0.022972679\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 140][  100/  391] loss: 0.018\n",
            "[ep 140][  200/  391] loss: 0.031\n",
            "[ep 140][  300/  391] loss: 0.048\n",
            "test loss 0.9396631\n",
            "test accuracy 83.98 %\n",
            "train loss 0.029839238\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 141][  100/  391] loss: 0.045\n",
            "[ep 141][  200/  391] loss: 0.023\n",
            "[ep 141][  300/  391] loss: 0.016\n",
            "test loss 0.9395121\n",
            "test accuracy 83.98 %\n",
            "train loss 0.010983361\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 142][  100/  391] loss: 0.058\n",
            "[ep 142][  200/  391] loss: 0.029\n",
            "[ep 142][  300/  391] loss: 0.105\n",
            "test loss 0.9394518\n",
            "test accuracy 83.98 %\n",
            "train loss 0.027436266\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 143][  100/  391] loss: 0.041\n",
            "[ep 143][  200/  391] loss: 0.032\n",
            "[ep 143][  300/  391] loss: 0.024\n",
            "test loss 0.93944114\n",
            "test accuracy 83.98 %\n",
            "train loss 0.07494155\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 144][  100/  391] loss: 0.036\n",
            "[ep 144][  200/  391] loss: 0.029\n",
            "[ep 144][  300/  391] loss: 0.013\n",
            "test loss 0.9396084\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014935817\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 145][  100/  391] loss: 0.019\n",
            "[ep 145][  200/  391] loss: 0.015\n",
            "[ep 145][  300/  391] loss: 0.019\n",
            "test loss 0.93960243\n",
            "test accuracy 83.97 %\n",
            "train loss 0.024353104\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 146][  100/  391] loss: 0.016\n",
            "[ep 146][  200/  391] loss: 0.021\n",
            "[ep 146][  300/  391] loss: 0.025\n",
            "test loss 0.93951476\n",
            "test accuracy 83.98 %\n",
            "train loss 0.043684974\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 147][  100/  391] loss: 0.015\n",
            "[ep 147][  200/  391] loss: 0.036\n",
            "[ep 147][  300/  391] loss: 0.029\n",
            "test loss 0.93958056\n",
            "test accuracy 83.98 %\n",
            "train loss 0.046803407\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 148][  100/  391] loss: 0.015\n",
            "[ep 148][  200/  391] loss: 0.045\n",
            "[ep 148][  300/  391] loss: 0.013\n",
            "test loss 0.9395162\n",
            "test accuracy 83.98 %\n",
            "train loss 0.008479767\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 149][  100/  391] loss: 0.025\n",
            "[ep 149][  200/  391] loss: 0.020\n",
            "[ep 149][  300/  391] loss: 0.033\n",
            "test loss 0.93965065\n",
            "test accuracy 83.98 %\n",
            "train loss 0.008248279\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 150][  100/  391] loss: 0.024\n",
            "[ep 150][  200/  391] loss: 0.035\n",
            "[ep 150][  300/  391] loss: 0.025\n",
            "test loss 0.9395265\n",
            "test accuracy 83.98 %\n",
            "train loss 0.023804152\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 151][  100/  391] loss: 0.040\n",
            "[ep 151][  200/  391] loss: 0.017\n",
            "[ep 151][  300/  391] loss: 0.015\n",
            "test loss 0.93965703\n",
            "test accuracy 83.98 %\n",
            "train loss 0.012110382\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 152][  100/  391] loss: 0.008\n",
            "[ep 152][  200/  391] loss: 0.030\n",
            "[ep 152][  300/  391] loss: 0.016\n",
            "test loss 0.9395105\n",
            "test accuracy 83.97 %\n",
            "train loss 0.019979743\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 153][  100/  391] loss: 0.017\n",
            "[ep 153][  200/  391] loss: 0.022\n",
            "[ep 153][  300/  391] loss: 0.061\n",
            "test loss 0.9395845\n",
            "test accuracy 83.98 %\n",
            "train loss 0.039733626\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 154][  100/  391] loss: 0.030\n",
            "[ep 154][  200/  391] loss: 0.015\n",
            "[ep 154][  300/  391] loss: 0.025\n",
            "test loss 0.93966913\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01789826\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 155][  100/  391] loss: 0.034\n",
            "[ep 155][  200/  391] loss: 0.037\n",
            "[ep 155][  300/  391] loss: 0.023\n",
            "test loss 0.93969536\n",
            "test accuracy 83.97 %\n",
            "train loss 0.009876115\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 156][  100/  391] loss: 0.015\n",
            "[ep 156][  200/  391] loss: 0.023\n",
            "[ep 156][  300/  391] loss: 0.019\n",
            "test loss 0.939552\n",
            "test accuracy 83.98 %\n",
            "train loss 0.012334765\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 157][  100/  391] loss: 0.064\n",
            "[ep 157][  200/  391] loss: 0.018\n",
            "[ep 157][  300/  391] loss: 0.029\n",
            "test loss 0.9394119\n",
            "test accuracy 83.98 %\n",
            "train loss 0.008882875\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 158][  100/  391] loss: 0.023\n",
            "[ep 158][  200/  391] loss: 0.016\n",
            "[ep 158][  300/  391] loss: 0.043\n",
            "test loss 0.9394753\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01477834\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 159][  100/  391] loss: 0.047\n",
            "[ep 159][  200/  391] loss: 0.014\n",
            "[ep 159][  300/  391] loss: 0.018\n",
            "test loss 0.9396035\n",
            "test accuracy 83.98 %\n",
            "train loss 0.040139697\n",
            "train accuracy 99.49 %\n",
            "--------------------------------------------------\n",
            "[ep 160][  100/  391] loss: 0.012\n",
            "[ep 160][  200/  391] loss: 0.013\n",
            "[ep 160][  300/  391] loss: 0.036\n",
            "test loss 0.9394642\n",
            "test accuracy 83.97 %\n",
            "train loss 0.016927967\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 161][  100/  391] loss: 0.016\n",
            "[ep 161][  200/  391] loss: 0.052\n",
            "[ep 161][  300/  391] loss: 0.065\n",
            "test loss 0.93961936\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014578996\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 162][  100/  391] loss: 0.015\n",
            "[ep 162][  200/  391] loss: 0.023\n",
            "[ep 162][  300/  391] loss: 0.009\n",
            "test loss 0.9394576\n",
            "test accuracy 83.98 %\n",
            "train loss 0.079674676\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 163][  100/  391] loss: 0.044\n",
            "[ep 163][  200/  391] loss: 0.017\n",
            "[ep 163][  300/  391] loss: 0.016\n",
            "test loss 0.93959373\n",
            "test accuracy 83.98 %\n",
            "train loss 0.019445095\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 164][  100/  391] loss: 0.032\n",
            "[ep 164][  200/  391] loss: 0.023\n",
            "[ep 164][  300/  391] loss: 0.027\n",
            "test loss 0.9394018\n",
            "test accuracy 83.98 %\n",
            "train loss 0.019747298\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 165][  100/  391] loss: 0.020\n",
            "[ep 165][  200/  391] loss: 0.045\n",
            "[ep 165][  300/  391] loss: 0.014\n",
            "test loss 0.93945646\n",
            "test accuracy 83.98 %\n",
            "train loss 0.023800006\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 166][  100/  391] loss: 0.041\n",
            "[ep 166][  200/  391] loss: 0.021\n",
            "[ep 166][  300/  391] loss: 0.029\n",
            "test loss 0.93942976\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014596755\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 167][  100/  391] loss: 0.045\n",
            "[ep 167][  200/  391] loss: 0.016\n",
            "[ep 167][  300/  391] loss: 0.018\n",
            "test loss 0.9395629\n",
            "test accuracy 83.98 %\n",
            "train loss 0.029529437\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 168][  100/  391] loss: 0.014\n",
            "[ep 168][  200/  391] loss: 0.045\n",
            "[ep 168][  300/  391] loss: 0.015\n",
            "test loss 0.93943965\n",
            "test accuracy 83.98 %\n",
            "train loss 0.02519324\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 169][  100/  391] loss: 0.041\n",
            "[ep 169][  200/  391] loss: 0.015\n",
            "[ep 169][  300/  391] loss: 0.027\n",
            "test loss 0.9396496\n",
            "test accuracy 83.98 %\n",
            "train loss 0.025671476\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 170][  100/  391] loss: 0.025\n",
            "[ep 170][  200/  391] loss: 0.010\n",
            "[ep 170][  300/  391] loss: 0.020\n",
            "test loss 0.93958265\n",
            "test accuracy 83.98 %\n",
            "train loss 0.018383138\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 171][  100/  391] loss: 0.021\n",
            "[ep 171][  200/  391] loss: 0.041\n",
            "[ep 171][  300/  391] loss: 0.024\n",
            "test loss 0.9395877\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03910014\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 172][  100/  391] loss: 0.038\n",
            "[ep 172][  200/  391] loss: 0.025\n",
            "[ep 172][  300/  391] loss: 0.019\n",
            "test loss 0.93955654\n",
            "test accuracy 83.98 %\n",
            "train loss 0.018241573\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 173][  100/  391] loss: 0.044\n",
            "[ep 173][  200/  391] loss: 0.058\n",
            "[ep 173][  300/  391] loss: 0.040\n",
            "test loss 0.93955374\n",
            "test accuracy 83.98 %\n",
            "train loss 0.051671226\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 174][  100/  391] loss: 0.030\n",
            "[ep 174][  200/  391] loss: 0.012\n",
            "[ep 174][  300/  391] loss: 0.028\n",
            "test loss 0.93943197\n",
            "test accuracy 83.98 %\n",
            "train loss 0.009536536\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 175][  100/  391] loss: 0.029\n",
            "[ep 175][  200/  391] loss: 0.033\n",
            "[ep 175][  300/  391] loss: 0.025\n",
            "test loss 0.9394236\n",
            "test accuracy 83.98 %\n",
            "train loss 0.11282767\n",
            "train accuracy 99.50 %\n",
            "--------------------------------------------------\n",
            "[ep 176][  100/  391] loss: 0.015\n",
            "[ep 176][  200/  391] loss: 0.059\n",
            "[ep 176][  300/  391] loss: 0.005\n",
            "test loss 0.9395813\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01589048\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 177][  100/  391] loss: 0.019\n",
            "[ep 177][  200/  391] loss: 0.027\n",
            "[ep 177][  300/  391] loss: 0.041\n",
            "test loss 0.939532\n",
            "test accuracy 83.98 %\n",
            "train loss 0.017942775\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 178][  100/  391] loss: 0.033\n",
            "[ep 178][  200/  391] loss: 0.020\n",
            "[ep 178][  300/  391] loss: 0.017\n",
            "test loss 0.93956035\n",
            "test accuracy 83.98 %\n",
            "train loss 0.00944853\n",
            "train accuracy 99.47 %\n",
            "--------------------------------------------------\n",
            "[ep 179][  100/  391] loss: 0.037\n",
            "[ep 179][  200/  391] loss: 0.013\n",
            "[ep 179][  300/  391] loss: 0.013\n",
            "test loss 0.939364\n",
            "test accuracy 83.98 %\n",
            "train loss 0.014896271\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 180][  100/  391] loss: 0.035\n",
            "[ep 180][  200/  391] loss: 0.030\n",
            "[ep 180][  300/  391] loss: 0.011\n",
            "test loss 0.9394199\n",
            "test accuracy 83.98 %\n",
            "train loss 0.0103508765\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 181][  100/  391] loss: 0.022\n",
            "[ep 181][  200/  391] loss: 0.007\n",
            "[ep 181][  300/  391] loss: 0.030\n",
            "test loss 0.93958956\n",
            "test accuracy 83.98 %\n",
            "train loss 0.059364885\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 182][  100/  391] loss: 0.030\n",
            "[ep 182][  200/  391] loss: 0.024\n",
            "[ep 182][  300/  391] loss: 0.018\n",
            "test loss 0.9397312\n",
            "test accuracy 83.98 %\n",
            "train loss 0.02666148\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 183][  100/  391] loss: 0.007\n",
            "[ep 183][  200/  391] loss: 0.026\n",
            "[ep 183][  300/  391] loss: 0.021\n",
            "test loss 0.9395664\n",
            "test accuracy 83.98 %\n",
            "train loss 0.036525227\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 184][  100/  391] loss: 0.029\n",
            "[ep 184][  200/  391] loss: 0.087\n",
            "[ep 184][  300/  391] loss: 0.025\n",
            "test loss 0.9395962\n",
            "test accuracy 83.98 %\n",
            "train loss 0.019243818\n",
            "train accuracy 99.59 %\n",
            "--------------------------------------------------\n",
            "[ep 185][  100/  391] loss: 0.020\n",
            "[ep 185][  200/  391] loss: 0.024\n",
            "[ep 185][  300/  391] loss: 0.025\n",
            "test loss 0.9397049\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03968169\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 186][  100/  391] loss: 0.040\n",
            "[ep 186][  200/  391] loss: 0.020\n",
            "[ep 186][  300/  391] loss: 0.030\n",
            "test loss 0.93953645\n",
            "test accuracy 83.97 %\n",
            "train loss 0.031634994\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 187][  100/  391] loss: 0.036\n",
            "[ep 187][  200/  391] loss: 0.034\n",
            "[ep 187][  300/  391] loss: 0.016\n",
            "test loss 0.93962705\n",
            "test accuracy 83.98 %\n",
            "train loss 0.023959063\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 188][  100/  391] loss: 0.048\n",
            "[ep 188][  200/  391] loss: 0.025\n",
            "[ep 188][  300/  391] loss: 0.024\n",
            "test loss 0.93957824\n",
            "test accuracy 83.98 %\n",
            "train loss 0.013910472\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 189][  100/  391] loss: 0.025\n",
            "[ep 189][  200/  391] loss: 0.017\n",
            "[ep 189][  300/  391] loss: 0.013\n",
            "test loss 0.93956834\n",
            "test accuracy 83.98 %\n",
            "train loss 0.03032134\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 190][  100/  391] loss: 0.021\n",
            "[ep 190][  200/  391] loss: 0.015\n",
            "[ep 190][  300/  391] loss: 0.052\n",
            "test loss 0.93944067\n",
            "test accuracy 83.98 %\n",
            "train loss 0.06341939\n",
            "train accuracy 99.58 %\n",
            "--------------------------------------------------\n",
            "[ep 191][  100/  391] loss: 0.081\n",
            "[ep 191][  200/  391] loss: 0.033\n",
            "[ep 191][  300/  391] loss: 0.025\n",
            "test loss 0.93953645\n",
            "test accuracy 83.98 %\n",
            "train loss 0.020232113\n",
            "train accuracy 99.52 %\n",
            "--------------------------------------------------\n",
            "[ep 192][  100/  391] loss: 0.016\n",
            "[ep 192][  200/  391] loss: 0.016\n",
            "[ep 192][  300/  391] loss: 0.052\n",
            "test loss 0.93947\n",
            "test accuracy 83.98 %\n",
            "train loss 0.034460917\n",
            "train accuracy 99.55 %\n",
            "--------------------------------------------------\n",
            "[ep 193][  100/  391] loss: 0.016\n",
            "[ep 193][  200/  391] loss: 0.017\n",
            "[ep 193][  300/  391] loss: 0.009\n",
            "test loss 0.93957394\n",
            "test accuracy 83.98 %\n",
            "train loss 0.02046759\n",
            "train accuracy 99.57 %\n",
            "--------------------------------------------------\n",
            "[ep 194][  100/  391] loss: 0.021\n",
            "[ep 194][  200/  391] loss: 0.018\n",
            "[ep 194][  300/  391] loss: 0.018\n",
            "test loss 0.93957317\n",
            "test accuracy 83.98 %\n",
            "train loss 0.037720405\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 195][  100/  391] loss: 0.045\n",
            "[ep 195][  200/  391] loss: 0.058\n",
            "[ep 195][  300/  391] loss: 0.018\n",
            "test loss 0.93964225\n",
            "test accuracy 83.98 %\n",
            "train loss 0.04205612\n",
            "train accuracy 99.48 %\n",
            "--------------------------------------------------\n",
            "[ep 196][  100/  391] loss: 0.030\n",
            "[ep 196][  200/  391] loss: 0.043\n",
            "[ep 196][  300/  391] loss: 0.011\n",
            "test loss 0.93958503\n",
            "test accuracy 83.98 %\n",
            "train loss 0.034906097\n",
            "train accuracy 99.56 %\n",
            "--------------------------------------------------\n",
            "[ep 197][  100/  391] loss: 0.026\n",
            "[ep 197][  200/  391] loss: 0.041\n",
            "[ep 197][  300/  391] loss: 0.057\n",
            "test loss 0.93953735\n",
            "test accuracy 83.98 %\n",
            "train loss 0.039049517\n",
            "train accuracy 99.54 %\n",
            "--------------------------------------------------\n",
            "[ep 198][  100/  391] loss: 0.022\n",
            "[ep 198][  200/  391] loss: 0.012\n",
            "[ep 198][  300/  391] loss: 0.009\n",
            "test loss 0.9395827\n",
            "test accuracy 83.98 %\n",
            "train loss 0.022018358\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n",
            "[ep 199][  100/  391] loss: 0.021\n",
            "[ep 199][  200/  391] loss: 0.059\n",
            "[ep 199][  300/  391] loss: 0.055\n",
            "test loss 0.9396987\n",
            "test accuracy 83.98 %\n",
            "train loss 0.039803293\n",
            "train accuracy 99.51 %\n",
            "--------------------------------------------------\n",
            "[ep 200][  100/  391] loss: 0.031\n",
            "[ep 200][  200/  391] loss: 0.052\n",
            "[ep 200][  300/  391] loss: 0.022\n",
            "test loss 0.93944895\n",
            "test accuracy 83.98 %\n",
            "train loss 0.01956069\n",
            "train accuracy 99.53 %\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Eclab\\anaconda3\\envs\\pytorch37\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True) \n",
        "model.conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "model.maxpool = Identity()\n",
        "model.fc = torch.nn.Linear(2048, num_classes)\n",
        "#print(model)\n",
        "model.to(device)\n",
        "save_path = './resnet50_SAM_model_ep200.pth'\n",
        "torch.save(model, save_path)\n",
        "stats_resnet50_SAM_ep200 = model_module_SAM(model, trainloader, testloader)\n",
        "np.save(\"stats_resnet50_SAM_ep200\",stats_resnet50_SAM_ep200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRCaFaSEyPP",
        "outputId": "f9dc1e17-cf1e-4b3d-ddad-33c8b5a41404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 13.33 %\n"
          ]
        }
      ],
      "source": [
        "# load trained model\n",
        "model = torch.load(\"./model.pth\")\n",
        "model.to(device)\n",
        "\n",
        "# fixed testing process\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ-vWfp5pcE2"
      },
      "source": [
        "Accuracy of the network on the 10000 test images: 60.19 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClqMY-sxSjSt",
        "outputId": "872dfaa3-d9f5-46ab-9002-02d3898790f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98M\tmodel.pth\n"
          ]
        }
      ],
      "source": [
        "# model = models.mobilenet_v3_large()\n",
        "# torch.save(model, \"./model.pth\")\n",
        "\n",
        "# see size of saved model\n",
        "! du -h model.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "adam+schedule.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43631bbb9ed14d59b3db96cc2611b9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56301a7fb8704a039aa75b6a6da58e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7b0ba64f47485f822596253f519610",
            "placeholder": "​",
            "style": "IPY_MODEL_f41ae248d3c945c6aa0a4e7f0ace37f4",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 147MB/s]"
          }
        },
        "6c7b0ba64f47485f822596253f519610": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9601075326d34a4aa5b10b2b97bdc1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04ac7f8dfd646d69aecf5e6a3a442de",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ece6d1b16bf1411b8265687d7bff48e5",
            "value": 102530333
          }
        },
        "964e52c6c4ff411ebc05a3f9167ea5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04ac7f8dfd646d69aecf5e6a3a442de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7061b708b734d67aa37369ae81d0b66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2455034718144608cfb3f2a78bd6e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2f02a019e5b4eae9b3e5c4b637d6f7a",
              "IPY_MODEL_9601075326d34a4aa5b10b2b97bdc1ff",
              "IPY_MODEL_56301a7fb8704a039aa75b6a6da58e63"
            ],
            "layout": "IPY_MODEL_43631bbb9ed14d59b3db96cc2611b9ae"
          }
        },
        "d2f02a019e5b4eae9b3e5c4b637d6f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7061b708b734d67aa37369ae81d0b66",
            "placeholder": "​",
            "style": "IPY_MODEL_964e52c6c4ff411ebc05a3f9167ea5bb",
            "value": "100%"
          }
        },
        "ece6d1b16bf1411b8265687d7bff48e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f41ae248d3c945c6aa0a4e7f0ace37f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
